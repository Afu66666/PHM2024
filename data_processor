import numpy as np
from scipy import signal
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler
import torch
from torch.utils.data import Dataset

class DataProcessor:
    def __init__(self, scaler_type='robust'):
        self.scaler_type = scaler_type
        self.scalers = {}
        
        self.freq_mapping = {20: 0, 40: 1, 60: 2}
        self.load_mapping = {0: 0, 1: 1, -1: 2}
        
        self.stft_params = {
            'fs': 1000,
            'nperseg': 1024,
            'noverlap': 768,
            'window': 'hann',
            'detrend': False,
            'return_onesided': True,
            'boundary': None,
            'padded': True,
            'axis': -2
        }
    
    def get_scaler(self, component_name, n_features):
        key = f"{component_name}_{n_features}"
        if key not in self.scalers:
            if self.scaler_type == 'standard':
                self.scalers[key] = StandardScaler()
            elif self.scaler_type == 'minmax':
                self.scalers[key] = MinMaxScaler()
            elif self.scaler_type == 'robust':
                self.scalers[key] = RobustScaler()
            elif self.scaler_type == 'maxabs':
                self.scalers[key] = MaxAbsScaler()
            else:
                self.scalers[key] = None
        return self.scalers[key]
    
    def normalize_signal(self, X, component_name=None, fit=False):
        if self.scaler_type == 'none':
            return X
            
        if component_name is None:
            component_name = 'default'
            
        n_features = X.shape[-1]
        
        original_shape = X.shape
        X_reshaped = X.reshape(-1, n_features)
        
        scaler = self.get_scaler(component_name, n_features)
        
        if scaler is None:
            return X
        
        if fit:
            X_normalized = scaler.fit_transform(X_reshaped)
        else:
            X_normalized = scaler.transform(X_reshaped)
            
        return X_normalized.reshape(original_shape)
    
    def encode_conditions_batch(self, conditions):
        result = {
            "freq_id": [],
            "load_id": [],
        }
        
        for i in range(len(conditions)):
            freq = conditions[i, 0]
            load = conditions[i, 1]
            
            freq_id = self.freq_mapping.get(freq, 0)
            load_id = self.load_mapping.get(load, 0)
            
            result["freq_id"].append(freq_id)
            result["load_id"].append(load_id)

        result["freq_id"] = np.array(result["freq_id"])
        result["load_id"] = np.array(result["load_id"])

        return result
    
    def repeat_to_target_length(self, signal, target_length):
        is_batch = len(signal.shape) == 3
        
        if is_batch:
            samples, current_length, n_features = signal.shape
            
            if current_length >= target_length:
                return signal[:, :target_length, :]
            
            repeats_needed = int(np.ceil(target_length / current_length))
            print(f"信号长度 {current_length} < 目标长度 {target_length}，将重复 {repeats_needed} 次")
            
            result = np.zeros((samples, target_length, n_features))
            for i in range(samples):
                repeated = np.tile(signal[i], (repeats_needed, 1))
                result[i] = repeated[:target_length, :]
                
            return result
        else:
            current_length, n_features = signal.shape
            
            if current_length >= target_length:
                return signal[:target_length, :]
            
            repeats_needed = int(np.ceil(target_length / current_length))
            
            repeated = np.tile(signal, (repeats_needed, 1))
            return repeated[:target_length, :]
    
    def apply_stft(self, signal_data, component_name=None, repeat_to=None, **kwargs):
        params = self.stft_params.copy()
        params.update(kwargs)
        
        if repeat_to is not None:
            signal_data = self.repeat_to_target_length(signal_data, repeat_to)
            
        normalized_data = self.normalize_signal(signal_data, component_name, fit=True)
        
        is_batch = len(signal_data.shape) == 3
        
        if not is_batch:
            timesteps, n_features = normalized_data.shape
            stft_results = []
            
            for i in range(n_features):
                f, t, Zxx = signal.stft(
                    normalized_data[:, i],
                    fs=params['fs'],
                    window=params['window'],
                    nperseg=params['nperseg'],
                    noverlap=params['noverlap'],
                    detrend=params['detrend'],
                    return_onesided=params['return_onesided'],
                    boundary=params['boundary'],
                    padded=params['padded']
                )
                stft_results.append(np.abs(Zxx))
            
            return np.stack(stft_results, axis=0)
        
        else:
            samples, timesteps, n_features = normalized_data.shape
            batch_stft_results = []
            
            for s in range(samples):
                sample_stft = []
                
                for i in range(n_features):
                    f, t, Zxx = signal.stft(
                        normalized_data[s, :, i],
                        fs=params['fs'],
                        window=params['window'],
                        nperseg=params['nperseg'],
                        noverlap=params['noverlap'],
                        detrend=params['detrend'],
                        return_onesided=params['return_onesided'],
                        boundary=params['boundary'],
                        padded=params['padded']
                    )
                    sample_stft.append(np.abs(Zxx))
                
                batch_stft_results.append(np.stack(sample_stft, axis=0))
            
            return np.stack(batch_stft_results, axis=0)
    
    def process_dataset(self, X, conditions, y=None, component_name=None, apply_stft=True, 
                        stft_params=None, repeat_to=None):
        condition_encoded = self.encode_conditions_batch(conditions)
        
        if apply_stft:
            params = stft_params or {}
            stft_images = self.apply_stft(X, component_name=component_name, 
                                         repeat_to=repeat_to, **params)
            return stft_images, condition_encoded, y
        
        if repeat_to is not None:
            X = self.repeat_to_target_length(X, repeat_to)
        
        normalized_data = self.normalize_signal(X, component_name=component_name, fit=True)
        return normalized_data, condition_encoded, y

class MultiComponentDataset(Dataset):
    def __init__(self, data_list, conditions, labels=None, transform=None, is_stft=True):
        self.data_list = data_list
        self.conditions = conditions
        self.labels = labels
        
        if transform is not None and not isinstance(transform, list):
            self.transform = [transform] * len(data_list)
        else:
            self.transform = transform
            
        self.is_stft = is_stft
        
        self.length = len(data_list[0])
        for i, data in enumerate(data_list):
            assert len(data) == self.length, f"部件{i}的数据长度与部件0不一致"
        
        assert len(conditions['freq_id']) == self.length, "工况数据与信号数据长度不一致"
        if labels is not None:
            assert len(labels) == self.length, "标签数据与信号数据长度不一致"
    
    def __len__(self):
        return self.length
    
    def __getitem__(self, idx):
        component_tensors = []
        
        for i, component_data in enumerate(self.data_list):
            sample = component_data[idx]
            
            if self.transform is not None and i < len(self.transform) and self.transform[i] is not None:
                sample = self.transform[i](sample)
                
            sample_tensor = torch.FloatTensor(sample)
            component_tensors.append(sample_tensor)
            
        freq_id = torch.LongTensor([self.conditions['freq_id'][idx]])
        load_id = torch.LongTensor([self.conditions['load_id'][idx]])
        
        if self.labels is not None:
            label = torch.LongTensor([self.labels[idx]])
            return component_tensors, freq_id, load_id, label
        
        return component_tensors, freq_id, load_id, None
