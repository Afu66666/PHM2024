import numpy as np
import torch
import torch.nn as nn
import os
import json
from pathlib import Path
import torchvision.models as models
import random
import torch.nn.functional as F

# 添加Hugging Face相关导入
try:
    from huggingface_hub import hf_hub_download, HfApi, list_models
    from transformers import AutoConfig, AutoModel
    HUGGINGFACE_AVAILABLE = True
except ImportError:
    print("警告: 未安装huggingface_hub或transformers库，将使用标准PyTorch模型。")
    print("可使用 'pip install huggingface_hub transformers' 安装。")
    HUGGINGFACE_AVAILABLE = False

# 添加timm库支持
try:
    import timm
    TIMM_AVAILABLE = True
except ImportError:
    print("警告: 未安装timm库，将使用标准PyTorch模型。")
    print("可使用 'pip install timm' 安装。")
    TIMM_AVAILABLE = False


class HuggingFaceModelManager:
    """管理Hugging Face预训练模型的下载和使用"""
    
    def __init__(self, cache_dir=None):
        """
        初始化Hugging Face模型管理器
        
        参数:
            cache_dir: 模型缓存目录，如果为None则使用默认路径
        """
        self.cache_dir = cache_dir or os.path.expanduser("~/huggingface_models")
        os.makedirs(self.cache_dir, exist_ok=True)
        
        # 映射模型名称到Hugging Face仓库ID
        self.model_mapping = {
            'resnet18': 'microsoft/resnet-18',
            'resnet34': 'microsoft/resnet-34',
            'resnet50': 'microsoft/resnet-50',
            'resnet101': 'microsoft/resnet-101',
            'googlenet': 'timm/googlenet', 
            'efficientnet_b0': 'timm/efficientnet_b0'
        }
        
        # 模型文件信息
        self.model_files = {
            'microsoft/resnet-18': {'weights': 'pytorch_model.bin', 'config': 'config.json'},
            'microsoft/resnet-34': {'weights': 'pytorch_model.bin', 'config': 'config.json'},
            'microsoft/resnet-50': {'weights': 'pytorch_model.bin', 'config': 'config.json'},
            'microsoft/resnet-101': {'weights': 'pytorch_model.bin', 'config': 'config.json'}
        }
        
        # 记录已下载的模型
        self.downloaded_models = {}
        
        # 设置timm缓存目录
        if cache_dir:
            os.environ['TORCH_HOME'] = cache_dir
    
    # 保留原方法以保持兼容性
    def download_model(self, model_name):
        """保留旧方法签名以保持兼容性"""
        # 使用timm时，这个方法不再需要下载权重
        if TIMM_AVAILABLE:
            print(f"使用timm库，无需手动下载{model_name}模型权重。")
            return {'model_name': model_name}
        else:
            # 如果timm不可用，保留原逻辑
            return self._download_model_original(model_name)
    
    def _download_model_original(self, model_name):
        """原始下载方法，现在作为备份"""
        if not HUGGINGFACE_AVAILABLE:
            print(f"警告: 未安装huggingface_hub库，无法下载{model_name}模型。")
            return None
        
        # 获取Hugging Face仓库ID
        repo_id = self.model_mapping.get(model_name)
        if not repo_id:
            print(f"警告: 未找到{model_name}的Hugging Face映射。")
            return None
        
        # 检查是否已下载
        if model_name in self.downloaded_models:
            print(f"模型{model_name}已下载，使用缓存版本。")
            return self.downloaded_models[model_name]
        
        # 获取文件信息
        files_info = self.model_files.get(repo_id)
        if not files_info:
            print(f"警告: 未找到{repo_id}的文件信息。")
            return None
        
        try:
            print(f"正在从Hugging Face下载{model_name}模型...")
            result = {}
            
            # 下载权重文件
            weights_path = hf_hub_download(
                repo_id=repo_id,
                filename=files_info['weights'],
                cache_dir=self.cache_dir
            )
            result['weights'] = weights_path
            
            # 下载配置文件
            config_path = hf_hub_download(
                repo_id=repo_id,
                filename=files_info['config'],
                cache_dir=self.cache_dir
            )
            result['config'] = config_path
            
            print(f"成功下载{model_name}模型:")
            print(f"  - 权重文件: {weights_path}")
            print(f"  - 配置文件: {config_path}")
            
            # 缓存结果
            self.downloaded_models[model_name] = result
            return result
            
        except Exception as e:
            print(f"下载{model_name}时出错: {e}")
            return None
    
    def load_model_weights(self, model_name, torchvision_model):
        """保留旧方法签名以保持兼容性"""
        # 这个方法将不再用于加载权重，由create_branch_with_timm替代
        print(f"使用timm库加载{model_name}，忽略传入的torchvision模型。")
        return torchvision_model


def create_branch_with_hf_weights(model_type, num_channels, pretrained=True, hf_manager=None):
    """
    使用timm库创建预训练模型分支
    
    参数:
        model_type: 模型类型，如'resnet18'
        num_channels: 输入通道数
        pretrained: 是否使用预训练权重
        hf_manager: 为了保持兼容性，现在不再使用
        
    返回:
        不含分类层的模型分支
    """
    try:
        # 准备timm模型名称
        timm_model_name = model_type
        
        # 创建timm模型，指定输入通道
        print(f"使用timm创建{model_type}模型，输入通道数: {num_channels}")
        model = timm.create_model(
            timm_model_name,
            pretrained=pretrained,
            in_chans=num_channels,  # 指定输入通道数
            num_classes=0,  # 返回特征，不包括分类器
        )
        
        print(f"成功加载{model_type}的timm预训练模型")
        return model
        
    except Exception as e:
        print(f"使用timm创建{model_type}时出错: {e}")
        return None


class CustomMultiComponentModel(nn.Module):
    """使用预训练权重的多部件故障诊断模型"""
    
    def __init__(self, branches, num_classes, working_condition=True):
        super().__init__()
        self.component_branches = nn.ModuleList(branches)
        self.working_condition = working_condition
        self.num_components = len(branches)
        
        # 特征维度，根据ResNet18
        feature_dim = 512
        
        # 工况嵌入
        if working_condition:
            self.freq_embedding = nn.Embedding(3, 32)  # 3种频率
            self.load_embedding = nn.Embedding(3, 32)  # 3种负载
            
        # 先处理视觉特征
        self.visual_fusion = nn.Sequential(
            nn.Linear(feature_dim * self.num_components, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.4)
        )

        # 处理工况特征
        self.condition_fusion = nn.Sequential(
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Dropout(0.3)
        )

        # 融合两种特征
        self.final_fusion = nn.Sequential(
            nn.Linear(128 + 32, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(64, num_classes)
        )
    
    def forward(self, x_list, freq_id=None, load_id=None):
        # 确保输入的部件数量与分支数量一致
        assert len(x_list) == self.num_components, f"Expected {self.num_components} components, got {len(x_list)}"
        
        # 从每个部件提取特征
        features = []
        for i, x in enumerate(x_list):
            feat = self.component_branches[i](x)
            # 平坦化特征
            if len(feat.shape) > 2:
                feat = feat.view(feat.size(0), -1)
            features.append(feat)
        
        # 拼接所有部件的特征
        combined_features = torch.cat(features, dim=1)
        
        freq_embed = self.freq_embedding(freq_id.squeeze())
        load_embed = self.load_embedding(load_id.squeeze())
        # 逐步融合工况与特征
        # 通过工况特征融合层
        condition_embedding = torch.cat([freq_embed, load_embed], dim=1)
        condition_hidden = self.condition_fusion(condition_embedding)
        # 通过视觉特征融合层
        feature_hidden = self.visual_fusion(combined_features)
        # 通过融合层
        output = self.final_fusion(torch.cat([feature_hidden, condition_hidden], dim=1))
        
        return output


# 从model_pretrain_improved.py添加的类和函数

class WorkingConditionAdapter(nn.Module):
    """工况适配器，根据工况动态调整特征"""
    def __init__(self, feature_dim=512, embed_dim=64):
        super().__init__()
        # 工况嵌入
        self.freq_embedding = nn.Embedding(3, embed_dim // 2)  # 3种频率
        self.load_embedding = nn.Embedding(3, embed_dim // 2)  # 3种负载
        
        # 工况编码器 - 将工况信息转换为调制参数
        self.condition_encoder = nn.Sequential(
            nn.Linear(embed_dim, embed_dim * 2),
            nn.BatchNorm1d(embed_dim * 2),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(embed_dim * 2, feature_dim * 2)  # 为每个特征生成缩放和偏移参数
        )
        
        # 初始化为中性值
        self.condition_encoder[-1].weight.data.mul_(0.1)
        self.condition_encoder[-1].bias.data.zero_()
    
    def forward(self, features, freq_id, load_id):
        """
        使用FiLM风格的工况调制
        
        参数:
            features: 输入特征 [batch_size, feature_dim]
            freq_id: 频率ID [batch_size]
            load_id: 负载ID [batch_size]
        """
        # 获取工况嵌入
        freq_embed = self.freq_embedding(freq_id.squeeze())
        load_embed = self.load_embedding(load_id.squeeze())
        
        # 合并工况信息
        condition = torch.cat([freq_embed, load_embed], dim=1)
        
        # 生成调制参数 (缩放和偏移)
        modulation = self.condition_encoder(condition)
        gamma, beta = torch.chunk(modulation, 2, dim=1)
        
        # 应用FiLM调制: y = gamma * x + beta
        # 让gamma围绕1波动，以保留原始信息
        gamma = gamma.mul(0.1).add(1.0)
        
        # 应用调制
        conditioned_features = features * gamma + beta
        
        return conditioned_features


class ImprovedMultiComponentModel(nn.Module):
    """增强的多部件故障诊断模型，改进工况适应能力"""
    
    def __init__(self, branches, num_classes, working_condition=True):
        super().__init__()
        self.component_branches = nn.ModuleList(branches)
        self.working_condition = working_condition
        self.num_components = len(branches)
        
        # 特征维度，根据ResNet18
        feature_dim = 512
        
        # 工况适配器 - 为每个分支添加一个工况适配器
        if working_condition:
            self.condition_adapters = nn.ModuleList([
                WorkingConditionAdapter(feature_dim) for _ in range(self.num_components)
            ])
            
            # 保留原始的工况嵌入用于全局使用
            self.freq_embedding = nn.Embedding(3, 32)  # 3种频率
            self.load_embedding = nn.Embedding(3, 32)  # 3种负载
        
        # 增强工况信息处理
        self.condition_fusion = nn.Sequential(
            nn.Linear(64, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
        )
        
        # 视觉特征融合
        self.visual_fusion = nn.Sequential(
            nn.Linear(feature_dim * self.num_components, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
        )
        
        # 最终融合层
        self.final_fusion = nn.Sequential(
            nn.Linear(128 + 128, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, num_classes)
        )
    
    def forward(self, x_list, freq_id=None, load_id=None):
        # 确保输入的部件数量与分支数量一致
        assert len(x_list) == self.num_components, f"Expected {self.num_components} components, got {len(x_list)}"
        
        # 收集所有部件的特征
        features = []
        for i, x in enumerate(x_list):
            # 通过该部件的分支获取特征
            feat = self.component_branches[i](x)
            
            # 平坦化特征
            if len(feat.shape) > 2:
                feat = feat.view(feat.size(0), -1)
                
            # 应用工况适配器
            if self.working_condition and hasattr(self, 'condition_adapters'):
                feat = self.condition_adapters[i](feat, freq_id, load_id)
                
            features.append(feat)
        
        # 拼接所有部件的特征
        combined_features = torch.cat(features, dim=1)
        
        # 处理工况信息
        freq_embed = self.freq_embedding(freq_id.squeeze())
        load_embed = self.load_embedding(load_id.squeeze())
        condition_embedding = torch.cat([freq_embed, load_embed], dim=1)
        
        # 通过工况融合和特征融合网络
        condition_hidden = self.condition_fusion(condition_embedding)
        visual_hidden = self.visual_fusion(combined_features)
        
        # 最终融合并分类
        final_features = torch.cat([visual_hidden, condition_hidden], dim=1)
        output = self.final_fusion(final_features)
        
        return output


def compute_mmd_loss(source_features, target_features):
    """
    计算最大均值差异(MMD)损失，用于域适应
    
    参数:
        source_features: 源域特征 [batch_size, feature_dim]
        target_features: 目标域特征 [batch_size, feature_dim]
        
    返回:
        mmd_loss: MMD损失值
    """
    # 使用多个带宽的高斯核
    def gaussian_kernel(x, y, sigma=1.0):
        size_x = x.size(0)
        size_y = y.size(0)
        dim = x.size(1)
        
        x = x.unsqueeze(1)  # (size_x, 1, dim)
        y = y.unsqueeze(0)  # (1, size_y, dim)
        
        tiled_x = x.expand(size_x, size_y, dim)
        tiled_y = y.expand(size_x, size_y, dim)
        
        kernel_input = (tiled_x - tiled_y).pow(2).sum(2) / float(dim)
        return torch.exp(-kernel_input / (2 * sigma**2))
    
    # 使用多个sigma值
    sigmas = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 15, 20]
    
    n_source = source_features.size(0)
    n_target = target_features.size(0)
    
    # 计算核矩阵
    xx, yy, xy = 0, 0, 0
    for sigma in sigmas:
        xx += gaussian_kernel(source_features, source_features, sigma)
        yy += gaussian_kernel(target_features, target_features, sigma)
        xy += gaussian_kernel(source_features, target_features, sigma)
    
    # 计算MMD^2
    mmd = xx.mean() + yy.mean() - 2 * xy.mean()
    
    return mmd


def freeze_pretrained_layers(model, unfreeze_layers=None):
    """
    冻结模型大部分层，只保留指定层可训练
    
    参数:
        model: 要冻结的模型
        unfreeze_layers: 不冻结的层名列表，例如["layer4", "fusion"]
    
    返回:
        model: 冻结后的模型
    """
    if unfreeze_layers is None:
        unfreeze_layers = []
        
    # 冻结分支组件层
    for i, branch in enumerate(model.component_branches):
        for name, param in branch.named_parameters():
            # 检查是否在不冻结的层列表中
            should_unfreeze = any(layer in name for layer in unfreeze_layers)
            
            # 冻结或解冻参数
            param.requires_grad = should_unfreeze
            
            # 调试信息 - 只显示第一个分支的详细信息
            if i == 0 and (name.endswith("weight") or "conv" in name):
                status = "可训练" if param.requires_grad else "已冻结"
                print(f"分支 {i}, 层: {name}, 状态: {status}")
    
    # 计算可训练参数数量
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    total_params = sum(p.numel() for p in model.parameters())
    
    print(f"可训练参数: {trainable_params:,d} / {total_params:,d} ({trainable_params/total_params*100:.2f}%)")
    
    return model


def train_model(
    model, train_loader, val_loader, device, 
    epochs=30, 
    lr=0.00005,  # 使用非常小的学习率
    weight_decay=0.01,  # 增大权重衰减
    freeze_pretrained=True,  # 是否冻结预训练层
    unfreeze_layers=None  # 哪些层不冻结
):
    """改进的训练模型函数，整合了冻结层和小学习率"""
    
    # 如果需要冻结层
    if freeze_pretrained:
        model = freeze_pretrained_layers(model, unfreeze_layers)
    
    # 构建优化器，使用更小的学习率
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.AdamW(
        filter(lambda p: p.requires_grad, model.parameters()), 
        lr=lr,
        weight_decay=weight_decay
    )
    
    # 使用更温和的学习率调度器
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.2, patience=8, min_lr=1e-6
    )
    
    train_losses = []
    val_losses = []
    train_accs = []
    val_accs = []
    best_val_acc = 0.0
    best_model = None
    best_epoch = 0
    patience = 15
    counter = 0
    
    # 防止overfitting的早停
    for epoch in range(epochs):
        # 训练模式
        model.train()
        train_loss = 0.0
        correct = 0
        total = 0
        
        for batch_idx, (inputs, freq_ids, load_ids, targets) in enumerate(train_loader):
            # 将数据移至设备
            inputs = [x.to(device) for x in inputs]
            freq_ids = freq_ids.to(device)
            load_ids = load_ids.to(device)
            targets = targets.to(device).long().squeeze()  # 确保long类型
            
            # 梯度清零
            optimizer.zero_grad()
            
            # 前向传播
            outputs = model(inputs, freq_ids, load_ids)
            
            # 计算损失
            loss = criterion(outputs, targets)
            
            # 反向传播与优化
            loss.backward()
            
            # 梯度裁剪，防止梯度爆炸
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # 统计
            train_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
            
            # 显示进度
            if (batch_idx + 1) % 5 == 0 or (batch_idx + 1) == len(train_loader):
                print(f'轮次: {epoch+1}/{epochs} | 批次: {batch_idx+1}/{len(train_loader)} | '
                      f'损失: {train_loss/(batch_idx+1):.4f} | '
                      f'准确率: {100.*correct/total:.2f}%')
        
        # 训练集平均损失和准确率
        train_loss = train_loss / len(train_loader)
        train_acc = 100. * correct / total
        train_losses.append(train_loss)
        train_accs.append(train_acc)
        
        # 验证模式
        model.eval()
        val_loss = 0.0
        correct = 0
        total = 0
        all_preds = []
        all_targets = []
        
        with torch.no_grad():
            for batch_idx, (inputs, freq_ids, load_ids, targets) in enumerate(val_loader):
                # 将数据移至设备
                inputs = [x.to(device) for x in inputs]
                freq_ids = freq_ids.to(device)
                load_ids = load_ids.to(device)
                targets = targets.to(device).long().squeeze()  # 确保long类型
                
                # 前向传播
                outputs = model(inputs, freq_ids, load_ids)
                
                # 计算损失
                loss = criterion(outputs, targets)
                
                # 统计
                val_loss += loss.item()
                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()
                
                # 收集预测和目标
                all_preds.extend(predicted.cpu().numpy())
                all_targets.extend(targets.cpu().numpy())
        
        # 验证集平均损失和准确率
        val_loss = val_loss / len(val_loader)
        val_acc = 100. * correct / total
        val_losses.append(val_loss)
        val_accs.append(val_acc)
        
        # 只调用一次scheduler
        old_lr = optimizer.param_groups[0]['lr']
        scheduler.step(val_loss)
        
        if optimizer.param_groups[0]['lr'] != old_lr:
            print(f'学习率从 {old_lr} 调整为 {optimizer.param_groups[0]["lr"]}')
        
        # 保存最佳模型
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model = {k: v.cpu().detach() for k, v in model.state_dict().items()}
            best_epoch = epoch
            counter = 0  # 重置早停计数器
        else:
            counter += 1
        
        # 打印预测分布
        print(f"验证集预测标签分布: {np.unique(all_preds, return_counts=True)}")
        print(f"验证集真实标签分布: {np.unique(all_targets, return_counts=True)}")
        
        print(f'轮次: {epoch+1}/{epochs} | '
              f'训练损失: {train_loss:.4f} | 训练准确率: {train_acc:.2f}% | '
              f'验证损失: {val_loss:.4f} | 验证准确率: {val_acc:.2f}%')
        
        # 早停机制
        if counter >= patience:
            print(f"早停! 验证准确率在 {patience} 轮内没有提升。")
            break
    
    # 返回最佳模型和训练历史
    history = {
        'train_loss': train_losses,
        'val_loss': val_losses,
        'train_acc': train_accs,
        'val_acc': val_accs,
        'best_epoch': best_epoch
    }
    
    print(f"最佳模型出现在第 {best_epoch+1} 轮，验证准确率: {best_val_acc:.2f}%")
    
    # 恢复最佳模型
    model.load_state_dict(best_model)
    
    return model, history


def train_with_domain_adaptation(
    model, 
    train_loader,
    val_loader,
    test_loader,
    device, 
    epochs=50,
    lr=0.0005, 
    weight_decay=0.01,
    freeze_pretrained=True,
    unfreeze_layers=None
):
    """
    使用域适应技术训练模型
    
    参数:
        model: 需要训练的模型
        train_loader: 训练集数据加载器
        val_loader: 验证集数据加载器
        test_loader: 测试集数据加载器(用于无监督域适应)
        device: 使用的设备
        epochs: 训练轮数
        lr: 学习率
        weight_decay: 权重衰减
        freeze_pretrained: 是否冻结预训练层
        unfreeze_layers: 不冻结的层名称
    """
    # 如果需要冻结层
    if freeze_pretrained:
        model = freeze_pretrained_layers(model, unfreeze_layers)
    
    # 损失函数和优化器
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.AdamW(
        filter(lambda p: p.requires_grad, model.parameters()),
        lr=lr,
        weight_decay=weight_decay
    )
    
    # 学习率调度器
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.2, patience=5, min_lr=1e-6
    )
    
    # 记录训练历史
    train_losses = []
    val_losses = []
    domain_losses = []
    train_accs = []
    val_accs = []
    
    best_val_acc = 0.0
    best_model = None
    best_epoch = 0
    patience = 15
    counter = 0
    
    # 获取无标签的测试数据，用于域适应
    test_samples = []
    test_freq_ids = []
    test_load_ids = []
    
    # 获取一部分测试数据用于域适应
    for inputs, freq_ids, load_ids, _ in test_loader:
        if len(test_samples) < 50:  # 限制数量
            test_samples.append([x.to(device) for x in inputs])
            test_freq_ids.append(freq_ids.to(device))
            test_load_ids.append(load_ids.to(device)) 
        else:
            break
            
    print(f"已收集 {len(test_samples)} 批次测试数据用于域适应")
    
    # 开始训练
    for epoch in range(epochs):
        # 训练模式
        model.train()
        train_loss = 0.0
        domain_loss = 0.0
        correct = 0
        total = 0
        
        for batch_idx, (inputs, freq_ids, load_ids, targets) in enumerate(train_loader):
            # 将数据移至设备
            inputs = [x.to(device) for x in inputs]
            freq_ids = freq_ids.to(device)
            load_ids = load_ids.to(device)
            targets = targets.to(device).long().squeeze()
            
            # 梯度清零
            optimizer.zero_grad()
            
            # 前向传播 - 分类任务
            outputs = model(inputs, freq_ids, load_ids)
            
            # 分类损失
            cls_loss = criterion(outputs, targets)
            
            # 域适应损失
            da_loss = 0.0
            
            # 每5个批次计算一次域适应损失
            if (batch_idx % 5 == 0 or batch_idx % 5 == 1) and test_samples:
                # 随机选择一个测试批次
                test_idx = random.randint(0, len(test_samples)-1)
                test_inputs = test_samples[test_idx]
                test_freq_id = test_freq_ids[test_idx]
                test_load_id = test_load_ids[test_idx]
                
                # 提取特征表示
                with torch.no_grad():
                    # 从源域(训练集)和目标域(测试集)收集特征
                    source_features = []
                    for i, x in enumerate(inputs):
                        feat = model.component_branches[i](x)
                        if len(feat.shape) > 2:
                            feat = feat.view(feat.size(0), -1)
                        source_features.append(feat)
                    source_features = torch.cat(source_features, dim=1)
                    
                    target_features = []
                    for i, x in enumerate(test_inputs):
                        feat = model.component_branches[i](x)
                        if len(feat.shape) > 2:
                            feat = feat.view(feat.size(0), -1)
                        target_features.append(feat)
                    target_features = torch.cat(target_features, dim=1)
                
                # 计算MMD损失
                da_loss = compute_mmd_loss(source_features, target_features)
                
                # 工况相关的特殊处理
                # 尝试找出频率相同但负载不同的样本对，鼓励它们特征相似
                source_freqs = freq_ids.squeeze()
                target_freqs = test_freq_id.squeeze()
                
                # 创建频率匹配矩阵 [source_batch, target_batch]
                same_freq_mask = torch.eq(source_freqs.unsqueeze(1), target_freqs.unsqueeze(0))
                
                if same_freq_mask.any():
                    # 对于频率相同的样本对，我们希望它们的特征更相似
                    src_indices, tgt_indices = torch.where(same_freq_mask)
                    if len(src_indices) > 0:
                        pair_limit = min(10, len(src_indices))  # 限制计算量
                        pair_indices = torch.randperm(len(src_indices))[:pair_limit]
                        
                        for i in range(pair_limit):
                            idx = pair_indices[i]
                            src_idx = src_indices[idx]
                            tgt_idx = tgt_indices[idx]
                            
                            src_feat = source_features[src_idx].unsqueeze(0)
                            tgt_feat = target_features[tgt_idx].unsqueeze(0)
                            da_loss += compute_mmd_loss(src_feat, tgt_feat) * 0.1
                
                # 调整域适应损失权重
                da_loss *= 0.1  # 设置域适应损失的权重
            
            # 总损失
            loss = cls_loss + da_loss
            
            # 反向传播与优化
            loss.backward()
            
            # 梯度裁剪，防止梯度爆炸
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # 统计
            train_loss += cls_loss.item()
            domain_loss += da_loss if isinstance(da_loss, float) else da_loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
            
            # 显示进度
            if (batch_idx + 1) % 5 == 0 or (batch_idx + 1) == len(train_loader):
                print(f'轮次: {epoch+1}/{epochs} | 批次: {batch_idx+1}/{len(train_loader)} | '
                      f'损失: {train_loss/(batch_idx+1):.4f} | '
                      f'域损失: {domain_loss/(batch_idx+1):.6f} | '
                      f'准确率: {100.*correct/total:.2f}%')
        
        # 训练集平均损失和准确率
        train_loss = train_loss / len(train_loader)
        domain_loss = domain_loss / len(train_loader)
        train_acc = 100. * correct / total
        train_losses.append(train_loss)
        domain_losses.append(domain_loss)
        train_accs.append(train_acc)
        
        # 验证模式
        model.eval()
        val_loss = 0.0
        correct = 0
        total = 0
        all_preds = []
        all_targets = []
        
        with torch.no_grad():
            for batch_idx, (inputs, freq_ids, load_ids, targets) in enumerate(val_loader):
                # 将数据移至设备
                inputs = [x.to(device) for x in inputs]
                freq_ids = freq_ids.to(device)
                load_ids = load_ids.to(device)
                targets = targets.to(device).long().squeeze()
                
                # 前向传播
                outputs = model(inputs, freq_ids, load_ids)
                
                # 计算损失
                loss = criterion(outputs, targets)
                
                # 统计
                val_loss += loss.item()
                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()
                
                # 收集预测和目标
                all_preds.extend(predicted.cpu().numpy())
                all_targets.extend(targets.cpu().numpy())
        
        # 验证集平均损失和准确率
        val_loss = val_loss / len(val_loader)
        val_acc = 100. * correct / total
        val_losses.append(val_loss)
        val_accs.append(val_acc)
        
        # 调用学习率调度器
        scheduler.step(val_loss)
        
        # 保存最佳模型
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model = {k: v.cpu().detach() for k, v in model.state_dict().items()}
            best_epoch = epoch
            counter = 0  # 重置早停计数器
        else:
            counter += 1
        
        # 打印验证结果
        print(f"验证集预测标签分布: {np.unique(all_preds, return_counts=True)}")
        print(f"验证集真实标签分布: {np.unique(all_targets, return_counts=True)}")
        
        print(f'轮次: {epoch+1}/{epochs} | '
              f'训练损失: {train_loss:.4f} | 训练准确率: {train_acc:.2f}% | '
              f'域损失: {domain_loss:.6f} | '
              f'验证损失: {val_loss:.4f} | 验证准确率: {val_acc:.2f}%')
        
        # 早停机制
        if counter >= patience:
            print(f"早停! 验证准确率在 {patience} 轮内没有提升。")
            break
    
    # 返回最佳模型和训练历史
    history = {
        'train_loss': train_losses,
        'val_loss': val_losses,
        'domain_loss': domain_losses,
        'train_acc': train_accs,
        'val_acc': val_accs,
        'best_epoch': best_epoch
    }
    
    print(f"最佳模型出现在第 {best_epoch+1} 轮，验证准确率: {best_val_acc:.2f}%")
    
    # 恢复最佳模型
    model.load_state_dict(best_model)
    
    return model, history


def evaluate_model(model, test_loader, device):
    """评估模型函数"""
    model.eval()
    correct = 0
    total = 0
    all_preds = []
    all_targets = []
    
    with torch.no_grad():
        for inputs, freq_ids, load_ids, targets in test_loader:
            # 将数据移至设备
            inputs = [x.to(device) for x in inputs]
            freq_ids = freq_ids.to(device)
            load_ids = load_ids.to(device)
            targets = targets.to(device).long().squeeze()
            
            # 前向传播
            outputs = model(inputs, freq_ids, load_ids)
            
            # 统计
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
            
            # 收集预测和目标
            all_preds.extend(predicted.cpu().numpy())
            all_targets.extend(targets.cpu().numpy())
    
    # 计算准确率
    accuracy = 100. * correct / total
    print(f'测试集准确率: {accuracy:.2f}%')
    
    return accuracy, all_preds, all_targets
