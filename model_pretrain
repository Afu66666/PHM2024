import os
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import timm

class HuggingFaceModelManager:
    def __init__(self, cache_dir=None):
        self.cache_dir = cache_dir or os.path.expanduser("~/huggingface_models")
        os.makedirs(self.cache_dir, exist_ok=True)
        
        # 映射模型名称到Hugging Face仓库ID
        self.model_mapping = {
            'resnet18': 'microsoft/resnet-18',
        }

    def download_model(self, model_name):
        print(f"使用timm库，无需手动下载{model_name}模型权重。")
        return {'model_name': model_name}
    
    def load_model_weights(self, model_name, torchvision_model):
        print(f"使用timm库加载{model_name}，忽略传入的torchvision模型。")
        return torchvision_model


def create_branch_with_hf_weights(model_type, num_channels, pretrained=True, hf_manager=None):
    try:
        # 准备timm模型名称
        timm_model_name = model_type
        
        # 创建timm模型，指定输入通道
        print(f"使用timm创建{model_type}模型，输入通道数: {num_channels}")
        model = timm.create_model(
            timm_model_name,
            pretrained=pretrained,
            in_chans=num_channels,
            num_classes=0,  # 返回特征，不包括分类器
        )
        
        print(f"成功加载{model_type}的timm预训练模型")
        return model
        
    except Exception as e:
        print(f"使用timm创建{model_type}时出错: {e}")
        return None


class WorkingConditionAdapter(nn.Module):
    def __init__(self, feature_dim=512, embed_dim=64):
        super().__init__()
        # 工况嵌入
        self.freq_embedding = nn.Embedding(3, embed_dim // 2)  # 3种频率
        self.load_embedding = nn.Embedding(3, embed_dim // 2)  # 3种负载
        
        # 工况编码器 - 将工况信息转换为调制参数
        self.condition_encoder = nn.Sequential(
            nn.Linear(embed_dim, embed_dim * 2),
            nn.BatchNorm1d(embed_dim * 2),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(embed_dim * 2, feature_dim * 2)  # 为每个特征生成缩放和偏移参数
        )
        
        # 初始化为中性值
        self.condition_encoder[-1].weight.data.mul_(0.1)
        self.condition_encoder[-1].bias.data.zero_()
    
    def forward(self, features, freq_id, load_id):
        # 获取工况嵌入
        freq_embed = self.freq_embedding(freq_id.squeeze())
        load_embed = self.load_embedding(load_id.squeeze())
        
        # 合并工况信息
        condition = torch.cat([freq_embed, load_embed], dim=1)
        
        # 生成调制参数 (缩放和偏移)
        modulation = self.condition_encoder(condition)
        gamma, beta = torch.chunk(modulation, 2, dim=1)
        
        # 应用FiLM调制: y = gamma * x + beta
        # 让gamma围绕1波动，以保留原始信息
        gamma = gamma.mul(0.1).add(1.0)
        
        # 应用调制
        conditioned_features = features * gamma + beta
        
        return conditioned_features


class ImprovedMultiComponentModel(nn.Module):
    def __init__(self, branches, num_classes, working_condition=True):
        super().__init__()
        self.component_branches = nn.ModuleList(branches)
        self.working_condition = working_condition
        self.num_components = len(branches)
        
        # 特征维度，根据ResNet18
        feature_dim = 512
        
        # 工况适配器 - 为每个分支添加一个工况适配器
        if working_condition:
            self.condition_adapters = nn.ModuleList([
                WorkingConditionAdapter(feature_dim) for _ in range(self.num_components)
            ])
            
            # 保留原始的工况嵌入用于全局使用
            self.freq_embedding = nn.Embedding(3, 32)  # 3种频率
            self.load_embedding = nn.Embedding(3, 32)  # 3种负载
        
        # 增强工况信息处理
        self.condition_fusion = nn.Sequential(
            nn.Linear(64, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
        )
        
        # 视觉特征融合
        self.visual_fusion = nn.Sequential(
            nn.Linear(feature_dim * self.num_components, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
        )
        
        # 最终融合层
        self.final_fusion = nn.Sequential(
            nn.Linear(128 + 128, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, num_classes)
        )
    
    def forward(self, x_list, freq_id=None, load_id=None):
        # 确保输入的部件数量与分支数量一致
        assert len(x_list) == self.num_components, f"Expected {self.num_components} components, got {len(x_list)}"
        
        # 收集所有部件的特征
        features = []
        for i, x in enumerate(x_list):
            # 通过该部件的分支获取特征
            feat = self.component_branches[i](x)
            
            # 平坦化特征
            if len(feat.shape) > 2:
                feat = feat.view(feat.size(0), -1)
                
            # 应用工况适配器
            if self.working_condition and hasattr(self, 'condition_adapters'):
                feat = self.condition_adapters[i](feat, freq_id, load_id)
                
            features.append(feat)
        
        # 拼接所有部件的特征
        combined_features = torch.cat(features, dim=1)
        
        # 处理工况信息
        freq_embed = self.freq_embedding(freq_id.squeeze())
        load_embed = self.load_embedding(load_id.squeeze())
        condition_embedding = torch.cat([freq_embed, load_embed], dim=1)
        
        # 通过工况融合和特征融合网络
        condition_hidden = self.condition_fusion(condition_embedding)
        visual_hidden = self.visual_fusion(combined_features)
        
        # 最终融合并分类
        final_features = torch.cat([visual_hidden, condition_hidden], dim=1)
        output = self.final_fusion(final_features)
        
        return output


def freeze_pretrained_layers(model, unfreeze_layers=None):
    if unfreeze_layers is None:
        unfreeze_layers = []
        
    # 冻结分支组件层
    for i, branch in enumerate(model.component_branches):
        for name, param in branch.named_parameters():
            # 检查是否在不冻结的层列表中
            should_unfreeze = any(layer in name for layer in unfreeze_layers)
            
            # 冻结或解冻参数
            param.requires_grad = should_unfreeze
            
            # 调试信息 - 只显示第一个分支的详细信息
            if i == 0 and (name.endswith("weight") or "conv" in name):
                status = "可训练" if param.requires_grad else "已冻结"
                print(f"分支 {i}, 层: {name}, 状态: {status}")
    
    # 计算可训练参数数量
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    total_params = sum(p.numel() for p in model.parameters())
    
    print(f"可训练参数: {trainable_params:,d} / {total_params:,d} ({trainable_params/total_params*100:.2f}%)")
    
    return model


def train_model(
    model, train_loader, val_loader, device, 
    epochs=30, 
    lr=0.00005,
    weight_decay=0.01,
    freeze_pretrained=True,
    unfreeze_layers=None
):
    # 如果需要冻结层
    if freeze_pretrained:
        model = freeze_pretrained_layers(model, unfreeze_layers)
    
    # 构建优化器，使用更小的学习率
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.AdamW(
        filter(lambda p: p.requires_grad, model.parameters()), 
        lr=lr,
        weight_decay=weight_decay
    )
    
    # 使用更温和的学习率调度器
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.2, patience=8, min_lr=1e-6
    )
    
    train_losses = []
    val_losses = []
    train_accs = []
    val_accs = []
    best_val_acc = 0.0
    best_model = None
    best_epoch = 0
    patience = 15
    counter = 0
    
    # 防止overfitting的早停
    for epoch in range(epochs):
        # 训练模式
        model.train()
        train_loss = 0.0
        correct = 0
        total = 0
        
        for batch_idx, (inputs, freq_ids, load_ids, targets) in enumerate(train_loader):
            # 将数据移至设备
            inputs = [x.to(device) for x in inputs]
            freq_ids = freq_ids.to(device)
            load_ids = load_ids.to(device)
            targets = targets.to(device).long().squeeze()
            
            # 梯度清零
            optimizer.zero_grad()
            
            # 前向传播
            outputs = model(inputs, freq_ids, load_ids)
            
            # 计算损失
            loss = criterion(outputs, targets)
            
            # 反向传播与优化
            loss.backward()
            
            # 梯度裁剪，防止梯度爆炸
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # 统计
            train_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
            
            # 显示进度
            if (batch_idx + 1) % 5 == 0 or (batch_idx + 1) == len(train_loader):
                print(f'轮次: {epoch+1}/{epochs} | 批次: {batch_idx+1}/{len(train_loader)} | '
                      f'损失: {train_loss/(batch_idx+1):.4f} | '
                      f'准确率: {100.*correct/total:.2f}%')
        
        # 训练集平均损失和准确率
        train_loss = train_loss / len(train_loader)
        train_acc = 100. * correct / total
        train_losses.append(train_loss)
        train_accs.append(train_acc)
        
        # 验证模式
        model.eval()
        val_loss = 0.0
        correct = 0
        total = 0
        all_preds = []
        all_targets = []
        
        with torch.no_grad():
            for batch_idx, (inputs, freq_ids, load_ids, targets) in enumerate(val_loader):
                # 将数据移至设备
                inputs = [x.to(device) for x in inputs]
                freq_ids = freq_ids.to(device)
                load_ids = load_ids.to(device)
                targets = targets.to(device).long().squeeze()
                
                # 前向传播
                outputs = model(inputs, freq_ids, load_ids)
                
                # 计算损失
                loss = criterion(outputs, targets)
                
                # 统计
                val_loss += loss.item()
                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()
                
                # 收集预测和目标
                all_preds.extend(predicted.cpu().numpy())
                all_targets.extend(targets.cpu().numpy())
        
        # 验证集平均损失和准确率
        val_loss = val_loss / len(val_loader)
        val_acc = 100. * correct / total
        val_losses.append(val_loss)
        val_accs.append(val_acc)
        
        # 只调用一次scheduler
        old_lr = optimizer.param_groups[0]['lr']
        scheduler.step(val_loss)
        
        if optimizer.param_groups[0]['lr'] != old_lr:
            print(f'学习率从 {old_lr} 调整为 {optimizer.param_groups[0]["lr"]}')
        
        # 保存最佳模型
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model = {k: v.cpu().detach() for k, v in model.state_dict().items()}
            best_epoch = epoch
            counter = 0  # 重置早停计数器
        else:
            counter += 1
        
        print(f'轮次: {epoch+1}/{epochs} | '
              f'训练损失: {train_loss:.4f} | 训练准确率: {train_acc:.2f}% | '
              f'验证损失: {val_loss:.4f} | 验证准确率: {val_acc:.2f}%')
        
        # 早停机制
        if counter >= patience:
            print(f"早停! 验证准确率在 {patience} 轮内没有提升。")
            break
    
    # 返回最佳模型和训练历史
    history = {
        'train_loss': train_losses,
        'val_loss': val_losses,
        'train_acc': train_accs,
        'val_acc': val_accs,
        'best_epoch': best_epoch
    }
    
    print(f"最佳模型出现在第 {best_epoch+1} 轮，验证准确率: {best_val_acc:.2f}%")
    
    # 恢复最佳模型
    model.load_state_dict(best_model)
    
    return model, history


def evaluate_model(model, test_loader, device):
    model.eval()
    correct = 0
    total = 0
    all_preds = []
    all_targets = []
    
    with torch.no_grad():
        for inputs, freq_ids, load_ids, targets in test_loader:
            inputs = [x.to(device) for x in inputs]
            freq_ids = freq_ids.to(device)
            load_ids = load_ids.to(device)
            targets = targets.to(device).long().squeeze()
            
            outputs = model(inputs, freq_ids, load_ids)
            
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
            
            all_preds.extend(predicted.cpu().numpy())
            all_targets.extend(targets.cpu().numpy())
    
    accuracy = 100. * correct / total
    print(f'测试集准确率: {accuracy:.2f}%')
    
    return accuracy, all_preds, all_targets
