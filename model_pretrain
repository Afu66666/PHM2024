import numpy as np
import torch
import torch.nn as nn
import os
import json
from pathlib import Path
import torchvision.models as models

# 添加Hugging Face相关导入
try:
    from huggingface_hub import hf_hub_download, HfApi, list_models
    from transformers import AutoConfig, AutoModel
    HUGGINGFACE_AVAILABLE = True
except ImportError:
    print("警告: 未安装huggingface_hub或transformers库，将使用标准PyTorch模型。")
    print("可使用 'pip install huggingface_hub transformers' 安装。")
    HUGGINGFACE_AVAILABLE = False

# 添加timm库支持
try:
    import timm
    TIMM_AVAILABLE = True
except ImportError:
    print("警告: 未安装timm库，将使用标准PyTorch模型。")
    print("可使用 'pip install timm' 安装。")
    TIMM_AVAILABLE = False


class HuggingFaceModelManager:
    """管理Hugging Face预训练模型的下载和使用"""
    
    def __init__(self, cache_dir=None):
        """
        初始化Hugging Face模型管理器
        
        参数:
            cache_dir: 模型缓存目录，如果为None则使用默认路径
        """
        self.cache_dir = cache_dir or os.path.expanduser("~/huggingface_models")
        os.makedirs(self.cache_dir, exist_ok=True)
        
        # 映射模型名称到Hugging Face仓库ID
        self.model_mapping = {
            'resnet18': 'microsoft/resnet-18',
            'resnet34': 'microsoft/resnet-34',
            'resnet50': 'microsoft/resnet-50',
            'resnet101': 'microsoft/resnet-101',
            'googlenet': 'timm/googlenet', 
            'efficientnet_b0': 'timm/efficientnet_b0'
        }
        
        # 模型文件信息
        self.model_files = {
            'microsoft/resnet-18': {'weights': 'pytorch_model.bin', 'config': 'config.json'},
            'microsoft/resnet-34': {'weights': 'pytorch_model.bin', 'config': 'config.json'},
            'microsoft/resnet-50': {'weights': 'pytorch_model.bin', 'config': 'config.json'},
            'microsoft/resnet-101': {'weights': 'pytorch_model.bin', 'config': 'config.json'}
        }
        
        # 记录已下载的模型
        self.downloaded_models = {}
        
        # 设置timm缓存目录
        if cache_dir:
            os.environ['TORCH_HOME'] = cache_dir
    
    # 保留原方法以保持兼容性
    def download_model(self, model_name):
        """保留旧方法签名以保持兼容性"""
        # 使用timm时，这个方法不再需要下载权重
        if TIMM_AVAILABLE:
            print(f"使用timm库，无需手动下载{model_name}模型权重。")
            return {'model_name': model_name}
        else:
            # 如果timm不可用，保留原逻辑
            return self._download_model_original(model_name)
    
    def _download_model_original(self, model_name):
        """原始下载方法，现在作为备份"""
        if not HUGGINGFACE_AVAILABLE:
            print(f"警告: 未安装huggingface_hub库，无法下载{model_name}模型。")
            return None
        
        # 获取Hugging Face仓库ID
        repo_id = self.model_mapping.get(model_name)
        if not repo_id:
            print(f"警告: 未找到{model_name}的Hugging Face映射。")
            return None
        
        # 检查是否已下载
        if model_name in self.downloaded_models:
            print(f"模型{model_name}已下载，使用缓存版本。")
            return self.downloaded_models[model_name]
        
        # 获取文件信息
        files_info = self.model_files.get(repo_id)
        if not files_info:
            print(f"警告: 未找到{repo_id}的文件信息。")
            return None
        
        try:
            print(f"正在从Hugging Face下载{model_name}模型...")
            result = {}
            
            # 下载权重文件
            weights_path = hf_hub_download(
                repo_id=repo_id,
                filename=files_info['weights'],
                cache_dir=self.cache_dir
            )
            result['weights'] = weights_path
            
            # 下载配置文件
            config_path = hf_hub_download(
                repo_id=repo_id,
                filename=files_info['config'],
                cache_dir=self.cache_dir
            )
            result['config'] = config_path
            
            print(f"成功下载{model_name}模型:")
            print(f"  - 权重文件: {weights_path}")
            print(f"  - 配置文件: {config_path}")
            
            # 缓存结果
            self.downloaded_models[model_name] = result
            return result
            
        except Exception as e:
            print(f"下载{model_name}时出错: {e}")
            return None
    
    def load_model_weights(self, model_name, torchvision_model):
        """保留旧方法签名以保持兼容性"""
        # 这个方法将不再用于加载权重，由create_branch_with_timm替代
        print(f"使用timm库加载{model_name}，忽略传入的torchvision模型。")
        return torchvision_model


def create_branch_with_hf_weights(model_type, num_channels, pretrained=True, hf_manager=None):
    """
    使用timm库创建预训练模型分支
    
    参数:
        model_type: 模型类型，如'resnet18'
        num_channels: 输入通道数
        pretrained: 是否使用预训练权重
        hf_manager: 为了保持兼容性，现在不再使用
        
    返回:
        不含分类层的模型分支
    """
    # 检查timm是否可用
    if not TIMM_AVAILABLE:
        print(f"警告: 未安装timm库，使用标准torchvision模型。")
        return _create_branch_with_torchvision(model_type, num_channels, pretrained)
    
    try:
        # 准备timm模型名称
        timm_model_name = model_type
        
        # 创建timm模型，指定输入通道
        print(f"使用timm创建{model_type}模型，输入通道数: {num_channels}")
        model = timm.create_model(
            timm_model_name,
            pretrained=pretrained,
            in_chans=num_channels,  # 指定输入通道数
            num_classes=0,  # 返回特征，不包括分类器
        )
        
        print(f"成功加载{model_type}的timm预训练模型")
        return model
        
    except Exception as e:
        print(f"使用timm创建{model_type}时出错: {e}")
        print(f"回退到torchvision模型...")
        return _create_branch_with_torchvision(model_type, num_channels, pretrained)


def _create_branch_with_torchvision(model_type, num_channels, pretrained):
    """
    使用torchvision创建模型分支（作为后备方案）
    
    参数:
        model_type: 模型类型，'resnet18'等
        num_channels: 输入通道数
        pretrained: 是否使用预训练权重
        
    返回:
        模型分支
    """
    # 检查是否可以使用torch内置预训练权重
    try:
        if model_type == 'resnet18':
            from torchvision.models.resnet import ResNet18_Weights
            weights = ResNet18_Weights.IMAGENET1K_V1 if pretrained else None
            model = models.resnet18(weights=weights)
        elif model_type == 'resnet34':
            from torchvision.models.resnet import ResNet34_Weights
            weights = ResNet34_Weights.IMAGENET1K_V1 if pretrained else None
            model = models.resnet34(weights=weights)
        elif model_type == 'resnet50':
            from torchvision.models.resnet import ResNet50_Weights
            weights = ResNet50_Weights.IMAGENET1K_V1 if pretrained else None
            model = models.resnet50(weights=weights)
        elif model_type == 'resnet101':
            from torchvision.models.resnet import ResNet101_Weights
            weights = ResNet101_Weights.IMAGENET1K_V1 if pretrained else None
            model = models.resnet101(weights=weights)
        elif model_type == 'googlenet':
            from torchvision.models.googlenet import GoogLeNet_Weights
            weights = GoogLeNet_Weights.IMAGENET1K_V1 if pretrained else None
            model = models.googlenet(weights=weights)
        else:
            model = models.resnet18(weights=None)
            print(f"警告: 不支持的模型类型: {model_type}，使用随机初始化的resnet18")
    except (ImportError, AttributeError):
        # 旧版本PyTorch支持
        print("使用旧版PyTorch API加载预训练模型")
        if model_type == 'resnet18':
            model = models.resnet18(pretrained=pretrained)
        elif model_type == 'resnet34':
            model = models.resnet34(pretrained=pretrained)
        elif model_type == 'resnet50':
            model = models.resnet50(pretrained=pretrained)
        elif model_type == 'resnet101':
            model = models.resnet101(pretrained=pretrained)
        elif model_type == 'googlenet':
            model = models.googlenet(pretrained=pretrained)
        else:
            model = models.resnet18(pretrained=False)
            print(f"警告: 不支持的模型类型: {model_type}，使用随机初始化的resnet18")
    
    # 修改第一层以支持不同通道数
    if num_channels != 3:
        if model_type.startswith('resnet'):
            original_conv = model.conv1
            model.conv1 = nn.Conv2d(
                num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False
            )
            # 初始化新层权重
            if pretrained:
                with torch.no_grad():
                    # 从3通道权重初始化
                    new_weight = torch.mean(original_conv.weight, dim=1, keepdim=True)
                    model.conv1.weight.copy_(new_weight.repeat(1, num_channels, 1, 1))
        elif model_type == 'googlenet':
            original_conv = model.conv1.conv
            model.conv1.conv = nn.Conv2d(
                num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False
            )
            # 初始化新层权重
            if pretrained:
                with torch.no_grad():
                    # 从3通道权重初始化
                    new_weight = torch.mean(original_conv.weight, dim=1, keepdim=True)
                    model.conv1.conv.weight.copy_(new_weight.repeat(1, num_channels, 1, 1))
    
    # 移除最后的分类层
    if model_type.startswith('resnet'):
        return nn.Sequential(*list(model.children())[:-1])
    elif model_type == 'googlenet':
        return nn.Sequential(*list(model.children())[:-1])


class CustomMultiComponentModel(nn.Module):
    """使用预训练权重的多部件故障诊断模型"""
    
    def __init__(self, branches, num_classes, working_condition=True):
        super().__init__()
        self.component_branches = nn.ModuleList(branches)
        self.working_condition = working_condition
        self.num_components = len(branches)
        
        # 特征维度，根据ResNet18
        feature_dim = 512
        
        # 工况嵌入
        if working_condition:
            self.freq_embedding = nn.Embedding(3, 32)  # 3种频率
            self.load_embedding = nn.Embedding(3, 32)  # 3种负载
            
            # 融合层 (特征+工况)
            self.fusion = nn.Sequential(
                nn.Linear(feature_dim * self.num_components + 64, 512),
                nn.BatchNorm1d(512),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(512, 256),
                nn.BatchNorm1d(256),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(256, num_classes)
            )
        else:
            # 只有特征的融合层
            self.fusion = nn.Sequential(
                nn.Linear(feature_dim * self.num_components, 512),
                nn.BatchNorm1d(512),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(512, 256),
                nn.BatchNorm1d(256),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(256, num_classes)
            )
    
    def forward(self, x_list, freq_id=None, load_id=None):
        # 确保输入的部件数量与分支数量一致
        assert len(x_list) == self.num_components, f"Expected {self.num_components} components, got {len(x_list)}"
        
        # 从每个部件提取特征
        features = []
        for i, x in enumerate(x_list):
            feat = self.component_branches[i](x)
            # 平坦化特征
            if len(feat.shape) > 2:
                feat = feat.view(feat.size(0), -1)
            features.append(feat)
        
        # 拼接所有部件的特征
        combined_features = torch.cat(features, dim=1)
        
        # 融合特征和工况信息
        if self.working_condition and freq_id is not None and load_id is not None:
            freq_embed = self.freq_embedding(freq_id.squeeze())
            load_embed = self.load_embedding(load_id.squeeze())
            
            # 拼接工况嵌入
            condition_embedding = torch.cat([freq_embed, load_embed], dim=1)
            
            # 拼接特征和工况
            combined = torch.cat([combined_features, condition_embedding], dim=1)
        else:
            combined = combined_features
        
        # 通过融合层
        output = self.fusion(combined)
        
        return output

def freeze_pretrained_layers(model, unfreeze_layers=None):
    """
    冻结模型大部分层，只保留指定层可训练
    
    参数:
        model: 要冻结的模型
        unfreeze_layers: 不冻结的层名列表，例如["layer4", "fusion"]
    
    返回:
        model: 冻结后的模型
    """
    if unfreeze_layers is None:
        unfreeze_layers = ["layer4", "fusion"]  # 默认只训练最后一个残差块和融合层
    
    # 冻结分支组件层
    for i, branch in enumerate(model.component_branches):
        for name, param in branch.named_parameters():
            # 检查是否在不冻结的层列表中
            should_unfreeze = any(layer in name for layer in unfreeze_layers)
            
            # 冻结或解冻参数
            param.requires_grad = should_unfreeze
            
            # 调试信息 - 只显示第一个分支的详细信息
            if i == 0 and (name.endswith("weight") or "conv" in name):
                status = "可训练" if param.requires_grad else "已冻结"
                print(f"分支 {i}, 层: {name}, 状态: {status}")
    
    # 保持融合层可训练
    for name, param in model.fusion.named_parameters():
        param.requires_grad = True
    
    # 保持工况嵌入层可训练
    if hasattr(model, "freq_embedding"):
        for param in model.freq_embedding.parameters():
            param.requires_grad = True
    
    if hasattr(model, "load_embedding"):
        for param in model.load_embedding.parameters():
            param.requires_grad = True
    
    # 计算可训练参数数量
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    total_params = sum(p.numel() for p in model.parameters())
    
    print(f"可训练参数: {trainable_params:,d} / {total_params:,d} ({trainable_params/total_params*100:.2f}%)")
    
    return model


def train_model(
    model, train_loader, val_loader, device, 
    epochs=30, 
    lr=0.00005,  # 使用非常小的学习率
    weight_decay=0.01,  # 增大权重衰减
    freeze_pretrained=True,  # 是否冻结预训练层
    unfreeze_layers=None  # 哪些层不冻结
):
    """改进的训练模型函数，整合了冻结层和小学习率"""
    
    # 如果需要冻结层
    if freeze_pretrained:
        model = freeze_pretrained_layers(model, unfreeze_layers)
    
    # 构建优化器，使用更小的学习率
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.AdamW(
        filter(lambda p: p.requires_grad, model.parameters()), 
        lr=lr,
        weight_decay=weight_decay
    )
    
    # 使用更温和的学习率调度器
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.2, patience=8, min_lr=1e-6, verbose=True
    )
    
    train_losses = []
    val_losses = []
    train_accs = []
    val_accs = []
    best_val_acc = 0.0
    best_model = None
    best_epoch = 0
    patience = 15
    counter = 0
    
    # 防止overfitting的早停
    for epoch in range(epochs):
        # 训练模式
        model.train()
        train_loss = 0.0
        correct = 0
        total = 0
        
        for batch_idx, (inputs, freq_ids, load_ids, condition_ids, targets) in enumerate(train_loader):
            # 将数据移至设备
            inputs = [x.to(device) for x in inputs]
            freq_ids = freq_ids.to(device)
            load_ids = load_ids.to(device)
            targets = targets.to(device).long().squeeze()  # 确保long类型
            
            # 梯度清零
            optimizer.zero_grad()
            
            # 前向传播
            outputs = model(inputs, freq_ids, load_ids)
            
            # 计算损失
            loss = criterion(outputs, targets)
            
            # 反向传播与优化
            loss.backward()
            
            # 梯度裁剪，防止梯度爆炸
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # 统计
            train_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
            
            # 显示进度
            if (batch_idx + 1) % 5 == 0 or (batch_idx + 1) == len(train_loader):
                print(f'轮次: {epoch+1}/{epochs} | 批次: {batch_idx+1}/{len(train_loader)} | '
                      f'损失: {train_loss/(batch_idx+1):.4f} | '
                      f'准确率: {100.*correct/total:.2f}%')
        
        # 训练集平均损失和准确率
        train_loss = train_loss / len(train_loader)
        train_acc = 100. * correct / total
        train_losses.append(train_loss)
        train_accs.append(train_acc)
        
        # 验证模式
        model.eval()
        val_loss = 0.0
        correct = 0
        total = 0
        all_preds = []
        all_targets = []
        
        with torch.no_grad():
            for batch_idx, (inputs, freq_ids, load_ids, condition_ids, targets) in enumerate(val_loader):
                # 将数据移至设备
                inputs = [x.to(device) for x in inputs]
                freq_ids = freq_ids.to(device)
                load_ids = load_ids.to(device)
                targets = targets.to(device).long().squeeze()  # 确保long类型
                
                # 前向传播
                outputs = model(inputs, freq_ids, load_ids)
                
                # 计算损失
                loss = criterion(outputs, targets)
                
                # 统计
                val_loss += loss.item()
                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()
                
                # 收集预测和目标
                all_preds.extend(predicted.cpu().numpy())
                all_targets.extend(targets.cpu().numpy())
        
        # 验证集平均损失和准确率
        val_loss = val_loss / len(val_loader)
        val_acc = 100. * correct / total
        val_losses.append(val_loss)
        val_accs.append(val_acc)
        
        # 只调用一次scheduler
        old_lr = optimizer.param_groups[0]['lr']
        scheduler.step(val_loss)
        
        if optimizer.param_groups[0]['lr'] != old_lr:
            print(f'学习率从 {old_lr} 调整为 {optimizer.param_groups[0]["lr"]}')
        
        # 保存最佳模型
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model = {k: v.cpu().detach() for k, v in model.state_dict().items()}
            best_epoch = epoch
            counter = 0  # 重置早停计数器
        else:
            counter += 1
        
        # 打印预测分布
        print(f"验证集预测标签分布: {np.unique(all_preds, return_counts=True)}")
        print(f"验证集真实标签分布: {np.unique(all_targets, return_counts=True)}")
        
        print(f'轮次: {epoch+1}/{epochs} | '
              f'训练损失: {train_loss:.4f} | 训练准确率: {train_acc:.2f}% | '
              f'验证损失: {val_loss:.4f} | 验证准确率: {val_acc:.2f}%')
        
        # 早停机制
        if counter >= patience:
            print(f"早停! 验证准确率在 {patience} 轮内没有提升。")
            break
    
    # 返回最佳模型和训练历史
    history = {
        'train_loss': train_losses,
        'val_loss': val_losses,
        'train_acc': train_accs,
        'val_acc': val_accs,
        'best_epoch': best_epoch
    }
    
    print(f"最佳模型出现在第 {best_epoch+1} 轮，验证准确率: {best_val_acc:.2f}%")
    
    # 恢复最佳模型
    model.load_state_dict(best_model)
    
    return model, history

def evaluate_model(model, test_loader, device):
    """评估模型函数"""
    model.eval()
    correct = 0
    total = 0
    all_preds = []
    all_targets = []
    
    with torch.no_grad():
        for inputs, freq_ids, load_ids, condition_ids, targets in test_loader:
            # 将数据移至设备
            inputs = [x.to(device) for x in inputs]
            freq_ids = freq_ids.to(device)
            load_ids = load_ids.to(device)
            targets = targets.to(device).long().squeeze()
            
            # 前向传播
            outputs = model(inputs, freq_ids, load_ids)
            
            # 统计
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
            
            # 收集预测和目标
            all_preds.extend(predicted.cpu().numpy())
            all_targets.extend(targets.cpu().numpy())
    
    # 计算准确率
    accuracy = 100. * correct / total
    print(f'测试集准确率: {accuracy:.2f}%')
    
    return accuracy, all_preds, all_targets
