import numpy as np
import torch
import torch.nn as nn
import random
import torch.nn.functional as F
from model_pretrain import freeze_pretrained_layers

class WorkingConditionAdapter(nn.Module):
    """工况适配器，根据工况动态调整特征"""
    def __init__(self, feature_dim=512, embed_dim=64):
        super().__init__()
        # 工况嵌入
        self.freq_embedding = nn.Embedding(3, embed_dim // 2)  # 3种频率
        self.load_embedding = nn.Embedding(3, embed_dim // 2)  # 3种负载
        
        # 工况编码器 - 将工况信息转换为调制参数
        self.condition_encoder = nn.Sequential(
            nn.Linear(embed_dim, embed_dim * 2),
            nn.BatchNorm1d(embed_dim * 2),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(embed_dim * 2, feature_dim * 2)  # 为每个特征生成缩放和偏移参数
        )
        
        # 初始化为中性值
        self.condition_encoder[-1].weight.data.mul_(0.1)
        self.condition_encoder[-1].bias.data.zero_()
    
    def forward(self, features, freq_id, load_id):
        """
        使用FiLM风格的工况调制
        
        参数:
            features: 输入特征 [batch_size, feature_dim]
            freq_id: 频率ID [batch_size]
            load_id: 负载ID [batch_size]
        """
        # 获取工况嵌入
        freq_embed = self.freq_embedding(freq_id.squeeze())
        load_embed = self.load_embedding(load_id.squeeze())
        
        # 合并工况信息
        condition = torch.cat([freq_embed, load_embed], dim=1)
        
        # 生成调制参数 (缩放和偏移)
        modulation = self.condition_encoder(condition)
        gamma, beta = torch.chunk(modulation, 2, dim=1)
        
        # 应用FiLM调制: y = gamma * x + beta
        # 让gamma围绕1波动，以保留原始信息
        gamma = gamma.mul(0.1).add(1.0)
        
        # 应用调制
        conditioned_features = features * gamma + beta
        
        return conditioned_features


class ImprovedMultiComponentModel(nn.Module):
    """增强的多部件故障诊断模型，改进工况适应能力"""
    
    def __init__(self, branches, num_classes, working_condition=True):
        super().__init__()
        self.component_branches = nn.ModuleList(branches)
        self.working_condition = working_condition
        self.num_components = len(branches)
        
        # 特征维度，根据ResNet18
        feature_dim = 512
        
        # 工况适配器 - 为每个分支添加一个工况适配器
        if working_condition:
            self.condition_adapters = nn.ModuleList([
                WorkingConditionAdapter(feature_dim) for _ in range(self.num_components)
            ])
            
            # 保留原始的工况嵌入用于全局使用
            self.freq_embedding = nn.Embedding(3, 32)  # 3种频率
            self.load_embedding = nn.Embedding(3, 32)  # 3种负载
        
        # 增强工况信息处理
        self.condition_fusion = nn.Sequential(
            nn.Linear(64, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
        )
        
        # 视觉特征融合
        self.visual_fusion = nn.Sequential(
            nn.Linear(feature_dim * self.num_components, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
        )
        
        # 最终融合层
        self.final_fusion = nn.Sequential(
            nn.Linear(128 + 128, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, num_classes)
        )
    
    def forward(self, x_list, freq_id=None, load_id=None):
        # 确保输入的部件数量与分支数量一致
        assert len(x_list) == self.num_components, f"Expected {self.num_components} components, got {len(x_list)}"
        
        # 收集所有部件的特征
        features = []
        for i, x in enumerate(x_list):
            # 通过该部件的分支获取特征
            feat = self.component_branches[i](x)
            
            # 平坦化特征
            if len(feat.shape) > 2:
                feat = feat.view(feat.size(0), -1)
                
            # 应用工况适配器
            if self.working_condition and hasattr(self, 'condition_adapters'):
                feat = self.condition_adapters[i](feat, freq_id, load_id)
                
            features.append(feat)
        
        # 拼接所有部件的特征
        combined_features = torch.cat(features, dim=1)
        
        # 处理工况信息
        freq_embed = self.freq_embedding(freq_id.squeeze())
        load_embed = self.load_embedding(load_id.squeeze())
        condition_embedding = torch.cat([freq_embed, load_embed], dim=1)
        
        # 通过工况融合和特征融合网络
        condition_hidden = self.condition_fusion(condition_embedding)
        visual_hidden = self.visual_fusion(combined_features)
        
        # 最终融合并分类
        final_features = torch.cat([visual_hidden, condition_hidden], dim=1)
        output = self.final_fusion(final_features)
        
        return output


def compute_mmd_loss(source_features, target_features):
    """
    计算最大均值差异(MMD)损失，用于域适应
    
    参数:
        source_features: 源域特征 [batch_size, feature_dim]
        target_features: 目标域特征 [batch_size, feature_dim]
        
    返回:
        mmd_loss: MMD损失值
    """
    # 使用多个带宽的高斯核
    def gaussian_kernel(x, y, sigma=1.0):
        size_x = x.size(0)
        size_y = y.size(0)
        dim = x.size(1)
        
        x = x.unsqueeze(1)  # (size_x, 1, dim)
        y = y.unsqueeze(0)  # (1, size_y, dim)
        
        tiled_x = x.expand(size_x, size_y, dim)
        tiled_y = y.expand(size_x, size_y, dim)
        
        kernel_input = (tiled_x - tiled_y).pow(2).sum(2) / float(dim)
        return torch.exp(-kernel_input / (2 * sigma**2))
    
    # 使用多个sigma值
    sigmas = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 15, 20]
    
    n_source = source_features.size(0)
    n_target = target_features.size(0)
    
    # 计算核矩阵
    xx, yy, xy = 0, 0, 0
    for sigma in sigmas:
        xx += gaussian_kernel(source_features, source_features, sigma)
        yy += gaussian_kernel(target_features, target_features, sigma)
        xy += gaussian_kernel(source_features, target_features, sigma)
    
    # 计算MMD^2
    mmd = xx.mean() + yy.mean() - 2 * xy.mean()
    
    return mmd


def train_with_domain_adaptation(
    model, 
    train_loader,
    val_loader,
    test_loader,
    device, 
    epochs=50,
    lr=0.0005, 
    weight_decay=0.01,
    freeze_pretrained=True,
    unfreeze_layers=None
):
    """
    使用域适应技术训练模型
    
    参数:
        model: 需要训练的模型
        train_loader: 训练集数据加载器
        val_loader: 验证集数据加载器
        test_loader: 测试集数据加载器(用于无监督域适应)
        device: 使用的设备
        epochs: 训练轮数
        lr: 学习率
        weight_decay: 权重衰减
        freeze_pretrained: 是否冻结预训练层
        unfreeze_layers: 不冻结的层名称
    """
    # 如果需要冻结层
    if freeze_pretrained:
        model = freeze_pretrained_layers(model, unfreeze_layers)
    
    # 损失函数和优化器
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.AdamW(
        filter(lambda p: p.requires_grad, model.parameters()),
        lr=lr,
        weight_decay=weight_decay
    )
    
    # 学习率调度器
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.2, patience=5, min_lr=1e-6
    )
    
    # 记录训练历史
    train_losses = []
    val_losses = []
    domain_losses = []
    train_accs = []
    val_accs = []
    
    best_val_acc = 0.0
    best_model = None
    best_epoch = 0
    patience = 15
    counter = 0
    
    # 获取无标签的测试数据，用于域适应
    test_samples = []
    test_freq_ids = []
    test_load_ids = []
    
    # 获取一部分测试数据用于域适应
    for inputs, freq_ids, load_ids, _ in test_loader:
        if len(test_samples) < 50:  # 限制数量
            test_samples.append([x.to(device) for x in inputs])
            test_freq_ids.append(freq_ids.to(device))
            test_load_ids.append(load_ids.to(device)) 
        else:
            break
            
    print(f"已收集 {len(test_samples)} 批次测试数据用于域适应")
    
    # 开始训练
    for epoch in range(epochs):
        # 训练模式
        model.train()
        train_loss = 0.0
        domain_loss = 0.0
        correct = 0
        total = 0
        
        for batch_idx, (inputs, freq_ids, load_ids, targets) in enumerate(train_loader):
            # 将数据移至设备
            inputs = [x.to(device) for x in inputs]
            freq_ids = freq_ids.to(device)
            load_ids = load_ids.to(device)
            targets = targets.to(device).long().squeeze()
            
            # 梯度清零
            optimizer.zero_grad()
            
            # 前向传播 - 分类任务
            outputs = model(inputs, freq_ids, load_ids)
            
            # 分类损失
            cls_loss = criterion(outputs, targets)
            
            # 域适应损失
            da_loss = 0.0
            
            # 每5个批次计算一次域适应损失
            if (batch_idx % 5 == 0 or batch_idx % 5 == 1) and test_samples:
                # 随机选择一个测试批次
                test_idx = random.randint(0, len(test_samples)-1)
                test_inputs = test_samples[test_idx]
                test_freq_id = test_freq_ids[test_idx]
                test_load_id = test_load_ids[test_idx]
                
                # 提取特征表示
                with torch.no_grad():
                    # 提取中间层特征 - 这里需要根据您模型的具体结构调整
                    # 在真实场景中，可能需要修改模型以返回中间层特征
                    
                    # 这里使用的是简化方法，仅供示例
                    # 实际实现中，可能需要添加一个提取特征的方法到模型中
                    
                    # 从源域(训练集)和目标域(测试集)收集特征
                    source_features = []
                    for i, x in enumerate(inputs):
                        feat = model.component_branches[i](x)
                        if len(feat.shape) > 2:
                            feat = feat.view(feat.size(0), -1)
                        source_features.append(feat)
                    source_features = torch.cat(source_features, dim=1)
                    
                    target_features = []
                    for i, x in enumerate(test_inputs):
                        feat = model.component_branches[i](x)
                        if len(feat.shape) > 2:
                            feat = feat.view(feat.size(0), -1)
                        target_features.append(feat)
                    target_features = torch.cat(target_features, dim=1)
                
                # 计算MMD损失
                da_loss = compute_mmd_loss(source_features, target_features)
                
                # 工况相关的特殊处理
                # 尝试找出频率相同但负载不同的样本对，鼓励它们特征相似
                source_freqs = freq_ids.squeeze()
                target_freqs = test_freq_id.squeeze()
                
                # 创建频率匹配矩阵 [source_batch, target_batch]
                same_freq_mask = torch.eq(source_freqs.unsqueeze(1), target_freqs.unsqueeze(0))
                
                if same_freq_mask.any():
                    # 对于频率相同的样本对，我们希望它们的特征更相似
                    src_indices, tgt_indices = torch.where(same_freq_mask)
                    if len(src_indices) > 0:
                        pair_limit = min(10, len(src_indices))  # 限制计算量
                        pair_indices = torch.randperm(len(src_indices))[:pair_limit]
                        
                        for i in range(pair_limit):
                            idx = pair_indices[i]
                            src_idx = src_indices[idx]
                            tgt_idx = tgt_indices[idx]
                            
                            src_feat = source_features[src_idx].unsqueeze(0)
                            tgt_feat = target_features[tgt_idx].unsqueeze(0)
                            da_loss += compute_mmd_loss(src_feat, tgt_feat) * 0.1
                
                # 调整域适应损失权重
                da_loss *= 0.1  # 设置域适应损失的权重
            
            # 总损失
            loss = cls_loss + da_loss
            
            # 反向传播与优化
            loss.backward()
            
            # 梯度裁剪，防止梯度爆炸
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # 统计
            train_loss += cls_loss.item()
            domain_loss += da_loss if isinstance(da_loss, float) else da_loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
            
            # 显示进度
            if (batch_idx + 1) % 5 == 0 or (batch_idx + 1) == len(train_loader):
                print(f'轮次: {epoch+1}/{epochs} | 批次: {batch_idx+1}/{len(train_loader)} | '
                      f'损失: {train_loss/(batch_idx+1):.4f} | '
                      f'域损失: {domain_loss/(batch_idx+1):.6f} | '
                      f'准确率: {100.*correct/total:.2f}%')
        
        # 训练集平均损失和准确率
        train_loss = train_loss / len(train_loader)
        domain_loss = domain_loss / len(train_loader)
        train_acc = 100. * correct / total
        train_losses.append(train_loss)
        domain_losses.append(domain_loss)
        train_accs.append(train_acc)
        
        # 验证模式
        model.eval()
        val_loss = 0.0
        correct = 0
        total = 0
        all_preds = []
        all_targets = []
        
        with torch.no_grad():
            for batch_idx, (inputs, freq_ids, load_ids, targets) in enumerate(val_loader):
                # 将数据移至设备
                inputs = [x.to(device) for x in inputs]
                freq_ids = freq_ids.to(device)
                load_ids = load_ids.to(device)
                targets = targets.to(device).long().squeeze()
                
                # 前向传播
                outputs = model(inputs, freq_ids, load_ids)
                
                # 计算损失
                loss = criterion(outputs, targets)
                
                # 统计
                val_loss += loss.item()
                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()
                
                # 收集预测和目标
                all_preds.extend(predicted.cpu().numpy())
                all_targets.extend(targets.cpu().numpy())
        
        # 验证集平均损失和准确率
        val_loss = val_loss / len(val_loader)
        val_acc = 100. * correct / total
        val_losses.append(val_loss)
        val_accs.append(val_acc)
        
        # 调用学习率调度器
        scheduler.step(val_loss)
        
        # 保存最佳模型
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model = {k: v.cpu().detach() for k, v in model.state_dict().items()}
            best_epoch = epoch
            counter = 0  # 重置早停计数器
        else:
            counter += 1
        
        # 打印验证结果
        print(f"验证集预测标签分布: {np.unique(all_preds, return_counts=True)}")
        print(f"验证集真实标签分布: {np.unique(all_targets, return_counts=True)}")
        
        print(f'轮次: {epoch+1}/{epochs} | '
              f'训练损失: {train_loss:.4f} | 训练准确率: {train_acc:.2f}% | '
              f'域损失: {domain_loss:.6f} | '
              f'验证损失: {val_loss:.4f} | 验证准确率: {val_acc:.2f}%')
        
        # 早停机制
        if counter >= patience:
            print(f"早停! 验证准确率在 {patience} 轮内没有提升。")
            break
    
    # 返回最佳模型和训练历史
    history = {
        'train_loss': train_losses,
        'val_loss': val_losses,
        'domain_loss': domain_losses,
        'train_acc': train_accs,
        'val_acc': val_accs,
        'best_epoch': best_epoch
    }
    
    print(f"最佳模型出现在第 {best_epoch+1} 轮，验证准确率: {best_val_acc:.2f}%")
    
    # 恢复最佳模型
    model.load_state_dict(best_model)
    
    return model, history
