import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from torch.utils.data import DataLoader, TensorDataset
import time
import random

class ConditionEncoder(nn.Module):
    """工况编码器 - 将工况信息编码为嵌入向量"""
    def __init__(self, condition_dim=5, embedding_dim=32):
        super(ConditionEncoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(condition_dim, 64),
            nn.ReLU(),
            nn.Linear(64, embedding_dim),
            nn.ReLU()
        )
    
    def forward(self, condition):
        return self.encoder(condition)

class ConditionalSTFTGenerator(nn.Module):
    """条件STFT图像生成器 - 考虑工况信息"""
    def __init__(self, latent_dim=100, condition_dim=5, channels=1, output_size=224):
        super(ConditionalSTFTGenerator, self).__init__()
        self.latent_dim = latent_dim
        self.output_size = output_size
        self.condition_dim = condition_dim
        
        # 工况编码器
        self.condition_encoder = ConditionEncoder(condition_dim, embedding_dim=32)
        
        # 初始特征图大小为输出的1/8
        self.init_size = output_size // 8  
        
        # 结合噪声和工况编码的线性层
        self.l1 = nn.Sequential(
            nn.Linear(latent_dim + 32, 128 * self.init_size * self.init_size)
        )
        
        # 上采样层 - 3次上采样，每次2倍，达到原始大小
        self.conv_blocks = nn.Sequential(
            nn.BatchNorm2d(128),
            nn.Upsample(scale_factor=2),  # 1/8 -> 1/4
            nn.Conv2d(128, 128, 3, stride=1, padding=1),
            nn.BatchNorm2d(128, 0.8),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Upsample(scale_factor=2),  # 1/4 -> 1/2
            nn.Conv2d(128, 64, 3, stride=1, padding=1),
            nn.BatchNorm2d(64, 0.8),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Upsample(scale_factor=2),  # 1/2 -> 1/1
            nn.Conv2d(64, 32, 3, stride=1, padding=1),
            nn.BatchNorm2d(32, 0.8),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(32, channels, 3, stride=1, padding=1),
            nn.Tanh()  # 输出范围[-1,1]
        )

    def forward(self, z, condition):
        # 编码工况
        c_embedding = self.condition_encoder(condition)
        
        # 连接噪声和工况编码
        z_c = torch.cat([z, c_embedding], dim=1)
        
        # 生成图像
        out = self.l1(z_c)
        out = out.view(out.shape[0], 128, self.init_size, self.init_size)
        img = self.conv_blocks(out)
        
        return img

class ConditionalSTFTDiscriminator(nn.Module):
    """条件STFT图像判别器 - 考虑工况信息"""
    def __init__(self, channels=1, input_size=224, condition_dim=5):
        super(ConditionalSTFTDiscriminator, self).__init__()
        
        self.input_size = input_size
        self.condition_dim = condition_dim
        
        # 工况编码器
        self.condition_encoder = ConditionEncoder(condition_dim, embedding_dim=32)
        
        # 判别器卷积块
        def discriminator_block(in_filters, out_filters, bn=True):
            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1)]
            if bn:
                block.append(nn.BatchNorm2d(out_filters, 0.8))
            block.append(nn.LeakyReLU(0.2, inplace=True))
            block.append(nn.Dropout2d(0.2))
            return block

        # 图像处理部分
        self.model = nn.Sequential(
            *discriminator_block(channels, 32, bn=False),
            *discriminator_block(32, 64),
            *discriminator_block(64, 128),
            *discriminator_block(128, 256),
        )
        
        # 动态计算特征图大小
        ds_size = input_size // (2**4)
        self.final_size = ds_size * ds_size * 256
        
        # 合并图像特征和工况特征的判别层
        self.adv_layer = nn.Sequential(
            nn.Linear(self.final_size + 32, 256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )

    def forward(self, img, condition):
        # 处理图像
        img_features = self.model(img)
        img_features_flat = img_features.view(img_features.shape[0], -1)
        
        # 编码工况
        c_embedding = self.condition_encoder(condition)
        
        # 合并图像特征和工况特征
        combined = torch.cat([img_features_flat, c_embedding], dim=1)
        
        # 输出有效性评分
        validity = self.adv_layer(combined)
        return validity

# 工况处理函数
def process_conditions(conditions_data, indices=None):
    """处理工况数据，转换为适合GAN使用的格式"""
    if indices is not None:
        # 如果提供了索引，只选取这些索引的工况
        freq_id = conditions_data["freq_id"][indices]
        load_id = conditions_data["load_id"][indices]

    else:
        # 否则使用所有工况
        freq_id = conditions_data["freq_id"]
        load_id = conditions_data["load_id"]

    
    # 组合工况特征
    conditions = np.column_stack([
        freq_id, load_id
    ]).astype(np.float32)
    
    return conditions

def train_conditional_stft_gan(real_data, real_conditions, classes, 
                              epochs=50, batch_size=8, latent_dim=100):
    """
    训练条件STFT GAN用于数据和工况联合增强
    
    参数:
        real_data: STFT数据，形状为[samples, channels, height, width]
        real_conditions: 工况数据，形状为[samples, condition_features]
        classes: 对应的类别标签
        epochs: 训练轮次
        batch_size: 批次大小
        latent_dim: 潜在空间维度
    
    返回:
        训练好的条件生成器
    """
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # 数据准备
    channels = real_data.shape[1]
    input_size = real_data.shape[2]  # 假设高宽相等
    condition_dim = real_conditions.shape[1]
    
    print(f"条件GAN输入 - 图像大小: {input_size}x{input_size}, 通道数: {channels}, 工况维度: {condition_dim}")
    
    # 初始化条件GAN
    generator = ConditionalSTFTGenerator(
        latent_dim, 
        condition_dim=condition_dim, 
        channels=channels, 
        output_size=input_size
    ).to(device)
    
    discriminator = ConditionalSTFTDiscriminator(
        channels=channels, 
        input_size=input_size,
        condition_dim=condition_dim
    ).to(device)
    
    # 损失函数和优化器
    adversarial_loss = nn.BCELoss()
    optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))
    
    # 转换为张量
    if isinstance(real_data, np.ndarray):
        real_data = torch.from_numpy(real_data).float()
    
    if isinstance(real_conditions, np.ndarray):
        real_conditions = torch.from_numpy(real_conditions).float()
    
    # 创建数据集和加载器
    dataset = TensorDataset(real_data, real_conditions, torch.tensor(classes, dtype=torch.long))
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    
    print("开始训练条件STFT-GAN用于数据和工况联合增强...")
    start_time = time.time()
    
    for epoch in range(epochs):
        for i, (imgs, conds, labels) in enumerate(dataloader):
            # 配置输入
            real_imgs = imgs.to(device)
            real_conds = conds.to(device)
            batch_size = real_imgs.size(0)
            
            # 标签
            valid = torch.ones(batch_size, 1, device=device)
            fake = torch.zeros(batch_size, 1, device=device)
            
            # -----------------
            #  训练生成器
            # -----------------
            optimizer_G.zero_grad()
            
            # 生成随机噪声
            z = torch.randn(batch_size, latent_dim, device=device)
            
            # 生成条件样本
            gen_imgs = generator(z, real_conds)
            
            # 生成器损失
            g_loss = adversarial_loss(discriminator(gen_imgs, real_conds), valid)
            
            g_loss.backward()
            optimizer_G.step()
            
            # -----------------
            #  训练判别器
            # -----------------
            optimizer_D.zero_grad()
            
            # 真实样本损失
            real_loss = adversarial_loss(discriminator(real_imgs, real_conds), valid)
            
            # 生成样本损失
            fake_loss = adversarial_loss(discriminator(gen_imgs.detach(), real_conds), fake)
            
            # 总判别器损失
            d_loss = (real_loss + fake_loss) / 2
            
            d_loss.backward()
            optimizer_D.step()
            
            # 打印进度
            if (i + 1) % 10 == 0:
                print(
                    f"[Epoch {epoch}/{epochs}] [Batch {i}/{len(dataloader)}] "
                    f"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]"
                )
        
        if (epoch + 1) % 10 == 0:
            elapsed = time.time() - start_time
            print(f"完成epoch {epoch+1}/{epochs} - 已用时间: {elapsed:.2f}秒")
    
    print(f"条件GAN训练完成! 总用时: {time.time() - start_time:.2f}秒")
    return generator

def generate_synthetic_samples_with_conditions(
    generator, conditions_by_class, num_samples_per_class, n_classes, 
    latent_dim=100, device=None
):
    """
    使用训练好的条件生成器为每个类别生成合成样本和对应的工况
    
    参数:
        generator: 训练好的条件生成器
        conditions_by_class: 按类别分组的工况数据字典
        num_samples_per_class: 每个类别生成的样本数
        n_classes: 类别数量
        latent_dim: 潜在空间维度
        device: 运行设备
    
    返回:
        synthetic_images: 合成图像
        synthetic_conditions: 合成工况
        synthetic_labels: 对应的标签
    """
    if device is None:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
    generator.eval()
    
    synthetic_images = []
    synthetic_conditions = []
    synthetic_labels = []
    
    with torch.no_grad():
        for class_idx in range(n_classes):
            if class_idx in conditions_by_class and len(conditions_by_class[class_idx]) > 0:
                # 为每个样本随机选择该类别的一个工况
                selected_conditions = []
                for _ in range(num_samples_per_class):
                    cond = random.choice(conditions_by_class[class_idx])
                    selected_conditions.append(cond)
                
                # 转换为张量
                conds_tensor = torch.tensor(np.array(selected_conditions), dtype=torch.float32).to(device)
                
                # 生成随机噪声
                z = torch.randn(num_samples_per_class, latent_dim, device=device)
                
                # 生成该类别和工况下的样本
                gen_imgs = generator(z, conds_tensor)
                
                # 保存生成的图像、工况和标签
                synthetic_images.append(gen_imgs.cpu())
                synthetic_conditions.extend(selected_conditions)
                synthetic_labels.extend([class_idx] * num_samples_per_class)
    
    # 拼接所有合成图像
    synthetic_images = torch.cat(synthetic_images, dim=0)
    synthetic_labels = torch.tensor(synthetic_labels, dtype=torch.long)
    synthetic_conditions = np.array(synthetic_conditions, dtype=np.float32)
    
    return synthetic_images, synthetic_conditions, synthetic_labels

def augment_dataset_with_gan(
    component_data_list, labels, component_names, conditions_data=None,
    epochs=30, samples_per_class=7
):
    """
    使用条件GAN对组件数据和工况数据进行联合增强
    
    参数:
        component_data_list: 组件数据列表，每个元素形状为[samples, channels, height, width]
        labels: 标签
        component_names: 组件名称列表
        conditions_data: 工况数据字典
        epochs: 训练GAN的轮次
        samples_per_class: 每个类别生成的样本数量
    
    返回:
        augmented_data_list: 增强后的组件数据列表
        augmented_labels: 增强后的标签
        augmented_conditions: 增强后的工况数据
    """
    n_classes = len(np.unique(labels))
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # 检查数据类型，记录原始数据是否为numpy数组以便最后转换回相同类型
    is_numpy_input = isinstance(component_data_list[0], np.ndarray)
    
    # 转为PyTorch张量
    if isinstance(labels, np.ndarray):
        labels_tensor = torch.tensor(labels, dtype=torch.long)
    else:
        labels_tensor = labels
    
    # 处理原始工况数据
    if conditions_data is None:
        print("警告: 没有提供工况数据，将使用随机工况...")
        # 创建随机工况作为后备方案
        random_conditions = np.random.rand(len(labels), 5).astype(np.float32)
        processed_conditions = random_conditions
    else:
        # 处理工况数据为模型可接受的格式
        processed_conditions = process_conditions(conditions_data)
    
    # 按类别组织工况数据，用于生成时的采样
    conditions_by_class = {}
    for i, label in enumerate(labels):
        class_idx = label if isinstance(label, int) else label.item()
        if class_idx not in conditions_by_class:
            conditions_by_class[class_idx] = []
        conditions_by_class[class_idx].append(processed_conditions[i])
    
    # 转换component_data_list为PyTorch张量
    tensor_component_data_list = []
    for data in component_data_list:
        if isinstance(data, np.ndarray):
            tensor_component_data_list.append(torch.tensor(data, dtype=torch.float32))
        else:
            tensor_component_data_list.append(data)
    
    print(f"使用条件GAN增强数据: 每个类别将生成{samples_per_class}个样本...")
    print(f"开始训练条件GAN并增强组件数据和工况数据...")
    
    # 存储所有合成的图像和条件（每个部件共享相同的新标签和工况）
    all_synthetic_images = []
    all_synthetic_conditions = None
    all_synthetic_labels = None
    
    for i, (component_data, name) in enumerate(zip(tensor_component_data_list, component_names)):
        print(f"处理组件 {name} ({i+1}/{len(tensor_component_data_list)})...")
        
        # 获取实际图像大小
        _, _, height, width = component_data.shape
        print(f"组件 {name} 的图像大小: {height}x{width}")
        
        # 确保输入图像是方形
        if height != width:
            raise ValueError(f"GAN目前只支持方形图像，但获得 {height}x{width}")
            
        # 训练该组件的条件GAN
        generator = train_conditional_stft_gan(
            component_data, 
            processed_conditions,
            labels, 
            epochs=epochs,
            batch_size=min(8, len(component_data)),
            latent_dim=100
        )
        
        # 生成合成样本和工况
        synthetic_images, synthetic_conditions, synthetic_labels = \
            generate_synthetic_samples_with_conditions(
                generator, 
                conditions_by_class, 
                samples_per_class, 
                n_classes,
                device=device
            )
        
        # 存储当前组件的合成图像
        all_synthetic_images.append(synthetic_images)
        
        # 只在第一个组件处理时存储合成的标签和工况
        if i == 0:
            all_synthetic_conditions = synthetic_conditions
            all_synthetic_labels = synthetic_labels
    
    # 创建增强后的数据列表
    augmented_data_list = []
    
    # 合并原始数据和合成数据 - 确保类型一致性
    for i, synthetic_images in enumerate(all_synthetic_images):
        # 确保component_data是PyTorch张量
        component_data = tensor_component_data_list[i]
        
        # 进行连接操作
        augmented_component = torch.cat([component_data, synthetic_images], dim=0)
        
        # 如果输入是numpy数组，则转换回numpy
        if is_numpy_input:
            augmented_component = augmented_component.detach().cpu().numpy()
            
        # 添加到结果列表
        augmented_data_list.append(augmented_component)
    
    # 合并标签
    augmented_labels = torch.cat([labels_tensor, all_synthetic_labels])
    
    # 构建增强后的工况数据结构
    if conditions_data is not None:
        # 从合成工况中提取各个字段
        synthetic_freq_id = all_synthetic_conditions[:, 0].astype(int)
        synthetic_load_id = all_synthetic_conditions[:, 1].astype(int)
        
        # 合并原始和合成工况
        augmented_conditions = {
            "freq_id": np.append(conditions_data["freq_id"], synthetic_freq_id),
            "load_id": np.append(conditions_data["load_id"], synthetic_load_id),
            
        }
    else:
        # 如果没有原始工况，使用所有合成工况
        augmented_conditions = {
            "freq_id": all_synthetic_conditions[:, 0].astype(int),
            "load_id": all_synthetic_conditions[:, 1].astype(int),
        }
    
    print(f"数据增强完成! 原始样本数: {len(labels)}, 增强后样本数: {len(augmented_labels)}")
    
    # 检查标签分布
    unique_labels, counts = np.unique(augmented_labels.numpy(), return_counts=True)
    print(f"增强后的标签分布: {list(zip(unique_labels, counts))}")
    
    # 将结果标签转换回numpy，以保持与原代码兼容
    if is_numpy_input:
        augmented_labels = augmented_labels.numpy()
    
    # 返回增强后的组件数据、标签和工况
    return augmented_data_list, augmented_labels, augmented_conditions
