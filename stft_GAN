import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from torch.utils.data import DataLoader, TensorDataset
import time

class STFTGenerator(nn.Module):
    """为STFT图像设计的生成器 - 适应可变输出大小"""
    def __init__(self, latent_dim=100, channels=1, output_size=224):
        super(STFTGenerator, self).__init__()
        self.latent_dim = latent_dim
        self.output_size = output_size
        
        # 初始特征图大小为输出的1/8
        self.init_size = output_size // 8  
        
        # 计算初始特征数量以匹配所需大小
        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size * self.init_size))
        
        # 上采样层 - 3次上采样，每次2倍，达到原始大小
        self.conv_blocks = nn.Sequential(
            nn.BatchNorm2d(128),
            nn.Upsample(scale_factor=2),  # 1/8 -> 1/4
            nn.Conv2d(128, 128, 3, stride=1, padding=1),
            nn.BatchNorm2d(128, 0.8),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Upsample(scale_factor=2),  # 1/4 -> 1/2
            nn.Conv2d(128, 64, 3, stride=1, padding=1),
            nn.BatchNorm2d(64, 0.8),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Upsample(scale_factor=2),  # 1/2 -> 1/1
            nn.Conv2d(64, 32, 3, stride=1, padding=1),
            nn.BatchNorm2d(32, 0.8),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(32, channels, 3, stride=1, padding=1),
            nn.Tanh()  # 输出范围[-1,1]
        )

    def forward(self, z, label=None):
        out = self.l1(z)
        out = out.view(out.shape[0], 128, self.init_size, self.init_size)
        img = self.conv_blocks(out)
        
        # 检查输出大小
        _, _, h, w = img.shape
        if h != self.output_size or w != self.output_size:
            print(f"警告: 生成器输出大小 ({h}x{w}) 与目标大小 ({self.output_size}x{self.output_size}) 不匹配")
            # 如有需要，可以在这里添加额外的大小调整
        
        return img

class STFTDiscriminator(nn.Module):
    """STFT图像判别器 - 处理可变大小的输入"""
    def __init__(self, channels=1, input_size=224):
        super(STFTDiscriminator, self).__init__()
        
        self.input_size = input_size
        
        def discriminator_block(in_filters, out_filters, bn=True):
            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1)]
            if bn:
                block.append(nn.BatchNorm2d(out_filters, 0.8))
            block.append(nn.LeakyReLU(0.2, inplace=True))
            block.append(nn.Dropout2d(0.2))
            return block

        self.model = nn.Sequential(
            *discriminator_block(channels, 32, bn=False),
            *discriminator_block(32, 64),
            *discriminator_block(64, 128),
            *discriminator_block(128, 256),
        )
        
        # 动态计算特征图大小
        # 每个discriminator_block将尺寸减半
        ds_size = input_size // (2**4)  
        self.final_size = ds_size * ds_size * 256
        
        # 输出层
        self.adv_layer = nn.Linear(self.final_size, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, img):
        # 获取输入图像大小并检查
        _, _, h, w = img.shape
        if h != self.input_size or w != self.input_size:
            print(f"注意：输入图像大小 ({h}x{w}) 与初始化大小 ({self.input_size}x{self.input_size}) 不匹配")
        
        features = self.model(img)
        features_flat = features.view(features.shape[0], -1)
        
        # 检查扁平化后的特征维度是否符合预期
        if features_flat.shape[1] != self.final_size:
            raise ValueError(
                f"特征维度不匹配: 期望 {self.final_size}, 实际 {features_flat.shape[1]}. "
                f"请调整判别器初始化时的 input_size 参数为 {h}"
            )
            
        validity = self.adv_layer(features_flat)
        return self.sigmoid(validity)

def train_stft_gan(real_data, classes, epochs=50, batch_size=8, latent_dim=100, sample_interval=200):
    """
    训练STFT GAN用于数据增强
    
    参数:
        real_data: STFT数据，形状为[samples, channels, height, width]
        classes: 对应的类别标签
        epochs: 训练轮次
        batch_size: 批次大小
        latent_dim: 潜在空间维度
        sample_interval: 每多少批次保存一次生成的样本
    
    返回:
        训练好的生成器
    """
    # 使用CPU训练GAN，避免与主模型抢GPU资源
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # 数据准备
    channels = real_data.shape[1]
    
    # 获取输入图像大小
    input_size = real_data.shape[2]  # 假设高宽相等
    print(f"GAN输入图像大小: {input_size}x{input_size}, 通道数: {channels}")
    
    # 初始化GAN - 使用正确的输入尺寸
    generator = STFTGenerator(latent_dim, channels).to(device)
    discriminator = STFTDiscriminator(channels, input_size=input_size).to(device)
    
    # 损失函数和优化器
    adversarial_loss = nn.BCELoss()
    optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))
    
    # 如果数据是numpy数组，转换为张量
    if isinstance(real_data, np.ndarray):
        real_data = torch.from_numpy(real_data).float()
    
    # 创建数据集和数据加载器
    dataset = TensorDataset(real_data, torch.tensor(classes, dtype=torch.long))
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    
    # 创建每个类别的条件向量
    n_classes = len(np.unique(classes))
    
    print("开始训练STFT-GAN用于数据增强...")
    start_time = time.time()
    
    for epoch in range(epochs):
        for i, (imgs, labels) in enumerate(dataloader):
            # 配置输入
            real_imgs = imgs.to(device)
            batch_size = real_imgs.size(0)
            
            # 创建真实和虚假标签
            valid = torch.ones(batch_size, 1, device=device)
            fake = torch.zeros(batch_size, 1, device=device)
            
            # -----------------
            #  训练生成器
            # -----------------
            optimizer_G.zero_grad()
            
            # 生成随机噪声
            z = torch.randn(batch_size, latent_dim, device=device)
            
            # 生成一批假图像
            gen_imgs = generator(z)
            
            # 计算生成器损失
            g_loss = adversarial_loss(discriminator(gen_imgs), valid)
            
            g_loss.backward()
            optimizer_G.step()
            
            # -----------------
            #  训练判别器
            # -----------------
            optimizer_D.zero_grad()
            
            # 计算真实图像和生成图像的损失
            real_loss = adversarial_loss(discriminator(real_imgs), valid)
            fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)
            d_loss = (real_loss + fake_loss) / 2
            
            d_loss.backward()
            optimizer_D.step()
            
            # 打印进度
            if (i + 1) % 10 == 0:
                print(
                    f"[Epoch {epoch}/{epochs}] [Batch {i}/{len(dataloader)}] "
                    f"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]"
                )
        
        if (epoch + 1) % 10 == 0:
            elapsed = time.time() - start_time
            print(f"完成epoch {epoch+1}/{epochs} - 已用时间: {elapsed:.2f}秒")
    
    print(f"GAN训练完成! 总用时: {time.time() - start_time:.2f}秒")
    return generator

def generate_synthetic_samples(generator, num_samples_per_class, n_classes, latent_dim=100):
    """
    使用训练好的生成器为每个类别生成合成样本
    
    参数:
        generator: 训练好的生成器
        num_samples_per_class: 每个类别生成的样本数
        n_classes: 类别数量
        latent_dim: 潜在空间维度
    
    返回:
        synthetic_images: 合成图像
        synthetic_labels: 对应的标签
    """
    device = generator.l1[0].weight.device
    generator.eval()
    
    synthetic_images = []
    synthetic_labels = []
    
    with torch.no_grad():
        for class_idx in range(n_classes):
            # 生成随机噪声
            z = torch.randn(num_samples_per_class, latent_dim, device=device)
            
            # 生成该类别的样本
            gen_imgs = generator(z)
            
            # 保存生成的图像和标签
            synthetic_images.append(gen_imgs.cpu())
            synthetic_labels.extend([class_idx] * num_samples_per_class)
    
    # 拼接所有合成图像
    synthetic_images = torch.cat(synthetic_images, dim=0)
    synthetic_labels = torch.tensor(synthetic_labels, dtype=torch.long)
    
    return synthetic_images, synthetic_labels

def augment_dataset_with_gan(
     component_data_list, labels, component_names, epochs=30, samples_per_class=7
):
    """
    使用GAN对每个组件数据进行增强
    
    参数:
        component_data_list: 组件数据列表，每个元素形状为[samples, channels, height, width]
        labels: 标签
        component_names: 组件名称列表
        epochs: 训练GAN的轮次
        samples_per_class: 每个类别生成的样本数量
    
    返回:
        augmented_data_list: 增强后的组件数据列表
        augmented_labels: 增强后的标签
    """
    n_classes = len(np.unique(labels))
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # 转为PyTorch张量
    if isinstance(labels, np.ndarray):
        labels = torch.tensor(labels, dtype=torch.long)
    
    augmented_data_list = [data.clone() if isinstance(data, torch.Tensor) else torch.tensor(data) 
                          for data in component_data_list]
    augmented_labels = labels.clone()
    
    print(f"使用GAN增强数据: 每个类别将生成{samples_per_class}个样本...")
    
    for i, (component_data, name) in enumerate(zip(component_data_list, component_names)):
        print(f"处理组件 {name} ({i+1}/{len(component_data_list)})...")
        
        # 确保数据是PyTorch张量
        if not isinstance(component_data, torch.Tensor):
            component_data = torch.tensor(component_data, dtype=torch.float32)
        
        # 获取实际图像大小
        _, _, height, width = component_data.shape
        print(f"组件 {name} 的图像大小: {height}x{width}")
        
        # 确保输入图像是方形
        if height != width:
            raise ValueError(f"GAN目前只支持方形图像，但获得 {height}x{width}")
            
        # 训练该组件的GAN - 使用正确的输出大小
        generator = train_stft_gan(
            component_data, 
            labels, 
            epochs=epochs,
            batch_size=min(8, len(component_data)),
            latent_dim=100
        )
        
        # 生成合成样本
        synthetic_images, synthetic_labels = generate_synthetic_samples(
            generator, samples_per_class, n_classes
        )
        
        # 合并原始数据和合成数据
        augmented_data_list[i] = torch.cat([component_data, synthetic_images], dim=0)
        
        # 只在第一个组件处理时更新标签(因为所有组件共享相同的标签)
        if i == 0:
            augmented_labels = torch.cat([labels, synthetic_labels])
    
    print(f"数据增强完成! 原始样本数: {len(labels)}, 增强后样本数: {len(augmented_labels)}")
    
    # 检查标签分布
    unique_labels, counts = np.unique(augmented_labels.numpy(), return_counts=True)
    print(f"增强后的标签分布: {list(zip(unique_labels, counts))}")
    
    # 将结果转换回numpy，以保持与原代码兼容
    augmented_data_list = [data.numpy() for data in augmented_data_list]
    augmented_labels = augmented_labels.numpy()
    
    return augmented_data_list, augmented_labels
